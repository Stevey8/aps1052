{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the missing code (#####). Here you learn to use the spearman_metric function. Check the very important question at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT:<br>\n",
    "We have argued that the Spearman Correlation and the Profit Factor are good non-linear losses or metrics <br>\n",
    "to measure the performance of many financial models, especially regression models. <br>\n",
    "\n",
    "Both TensorFlow/Keras and Scikit-Learn allow custom metrics (scoring functions). <br>\n",
    "Only TensorFlow/Keras allows custom losses (cost functions). <br>\n",
    "\n",
    "TensorFlow/Keras custom metrics are relatively easy to program. <br>\n",
    "TensorFlow/Keras custom losses are hard: they need to be differentiable. <br>\n",
    "\n",
    "In this notebook, <br>\n",
    "we have programmed a custom spearman_correlation_loss, which <br>\n",
    "is differentiable but an rough approximation to the real spearman correlation.<br>\n",
    "Unfortunately, <br>\n",
    "the neural network cannot learn well with this custom spearman_correlation_loss (you can try this below). <br>\n",
    "So, for now, if you want to use the Spearman Correlation at all with TensorFlow/Keras, <br>\n",
    "you can only use it as a metric and not as a loss.<br>\n",
    "This may change in the future. <br>\n",
    "\n",
    "In this notebook you will learn to use the combination of loss=mean squared error and metric= spearman correlation.<br>\n",
    "In fact, the combination of loss=mean squared error and metric=any list of metrics is possible.<br>\n",
    "    \n",
    "    \n",
    "It is also possible to use the combination loss=pearson correlation and metric=any list of metrics. <br>\n",
    "See: 5.pearson_corr_incomplete.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "# from keras.layers import Dense\n",
    "# from keras.models import Sequential\n",
    "# from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "# import keras.backend as K\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow.keras.backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see how to calculate the spearman correlation using numpy (1a), tensors (1b) and scipy.stats.spearmanr (3).\n",
    "The results are similar. The comparison is in 3.\n",
    "See: https://archive.md/VfNkG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 spearman from scratch using numpy\n",
    "def spearman_correlation(predictions, targets):\n",
    "    if not isinstance(predictions, pd.Series):\n",
    "        predictions = pd.Series(predictions)\n",
    "    ranked_preds = predictions.rank(pct = True, method = \"first\")\n",
    "    return np.corrcoef(ranked_preds, targets)[0, 1]\n",
    "\n",
    "#2 spearman from scratch using tensors\n",
    "def corrcoef(x, y):\n",
    "    mx = tf.math.reduce_mean(x)\n",
    "    my = tf.math.reduce_mean(y)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = tf.math.reduce_sum(xm * ym)\n",
    "    r_den = tf.norm(xm) * tf.norm(ym)\n",
    "    return r_num / (r_den + tf.keras.backend.epsilon())\n",
    "\n",
    "#3 spearman using tensors\n",
    "def tf_spearman_correlation(predictions, targets):\n",
    "    ranked_preds = tf.cast(tf.argsort(tf.argsort(predictions, stable = True)), targets.dtype)\n",
    "    return corrcoef(ranked_preds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use tensors to program a spearman metric. Note the use of py_func (a shortcut)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "py_func is a tf wrapper for a python function. py_func returns a tensor.\n",
    "Below we use py_func to wrap around the python function spearmanr.\n",
    "This use of py_func works in my setup but it does not always work.\n",
    "If you have problems with it, \n",
    "just use the spearman_metric underneath (commented out) that uses tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 spearman using scipy\n",
    "def spearman_metric(y_true, y_pred):\n",
    "    \"\"\"Spearman correlation coefficient using a tf wrapper for a python function\"\"\"\n",
    "    r = tf.py_function(spearmanr, inp=[y_true, y_pred], Tout=tf.float32)\n",
    "    return  r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use tensors to program a spearman loss that is compatible with Keras and TensorFlow. Note the argsort operation, which is not differentiable, cannot be used, so we use soft_rank instead. soft_rank gives approximate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 spearman using soft_rank\n",
    "def soft_rank(x, epsilon=1e-6):\n",
    "    pairwise_differences = x[:, None] - x[None, :]\n",
    "    abs_diff = tf.abs(pairwise_differences)\n",
    "    soft_rank = tf.reduce_sum(1 / (1 + abs_diff / epsilon), axis=1)\n",
    "    return soft_rank\n",
    "\n",
    "\n",
    "def spearman_correlation_loss(y_true, y_pred):\n",
    "    y_true_rank = soft_rank(y_true)\n",
    "    y_pred_rank = soft_rank(y_pred)\n",
    "\n",
    "    mean_y_true_rank = tf.reduce_mean(y_true_rank)\n",
    "    mean_y_pred_rank = tf.reduce_mean(y_pred_rank)\n",
    "\n",
    "    covariance = tf.reduce_mean((y_true_rank - mean_y_true_rank) * (y_pred_rank - mean_y_pred_rank))\n",
    "    std_y_true_rank = tf.math.reduce_std(y_true_rank)\n",
    "    std_y_pred_rank = tf.math.reduce_std(y_pred_rank)\n",
    "\n",
    "    epsilon = 1e-6\n",
    "    spearman_corr = covariance / (std_y_true_rank * std_y_pred_rank + epsilon)\n",
    "    scaling_factor = 100000 \n",
    "    return -spearman_corr*scaling_factor\n",
    "#note: A neural network training process minimizes the loss, so a negative Spearman correlation loss ensures that maximizing the correlation reduces the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman using numpy: -0.09999999999999996\n",
      "Spearman using tensors: -0.1\n",
      "Spearman using scipy: -0.1\n",
      "Spearman using soft_rank: 3.8585856\n"
     ]
    }
   ],
   "source": [
    "# Use of these functions\n",
    "targets = np.array([0.0, 0.25, 0.5, 0.75, 1.0], dtype = np.float32)\n",
    "predictions = np.random.rand(targets.shape[0])\n",
    "\n",
    "print(\"Spearman using numpy:\", spearman_correlation(predictions, targets))\n",
    "\n",
    "# result1 = tf_spearman_correlation(tf.convert_to_tensor(predictions, dtype=tf.float32), tf.convert_to_tensor(targets, dtype=tf.float32))\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     print(\"Spearman using tensors:\", sess.run(result1))\n",
    "\n",
    "result1 = tf_spearman_correlation(\n",
    "    tf.convert_to_tensor(predictions, dtype=tf.float32),\n",
    "    tf.convert_to_tensor(targets, dtype=tf.float32)\n",
    ")\n",
    "\n",
    "print(\"Spearman using tensors:\", result1.numpy())\n",
    "\n",
    "# Spearman using scipy\n",
    "# result2 = spearman_metric(targets, predictions)\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     print(\"Spearman using scipy:\", sess.run(result2))\n",
    "\n",
    "result2 = spearman_metric(\n",
    "    tf.convert_to_tensor(targets, dtype=tf.float32),\n",
    "    tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    ")\n",
    "\n",
    "print(\"Spearman using scipy:\", result2.numpy())\n",
    "\n",
    "\n",
    "# Spearman using soft_rank\n",
    "# result3 = spearman_correlation_loss(tf.convert_to_tensor(targets, dtype=tf.float32), tf.convert_to_tensor(predictions, dtype=tf.float32))\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     print(\"Spearman using soft_rank:\", -sess.run(result3)) #multiply by negative to undo the negative sign in the loss function\n",
    "result3 = spearman_correlation_loss(\n",
    "    tf.convert_to_tensor(targets, dtype=tf.float32),\n",
    "    tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    ")\n",
    "\n",
    "print(\"Spearman using soft_rank:\", -result3.numpy())  # negate to convert loss to positive correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=num_features, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainX)\n",
    "# transform training dataset\n",
    "trainX = scaler.transform(trainX)\n",
    "# transform test dataset\n",
    "testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevey/cpsc330arm/lib/python3.11/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take the length of shape with unknown rank.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      7\u001b[39m model.compile(loss=spearman_correlation_loss,\n\u001b[32m      8\u001b[39m               optimizer=SGD(learning_rate=\u001b[32m0.01\u001b[39m, momentum=\u001b[32m0.9\u001b[39m),\n\u001b[32m      9\u001b[39m               metrics=[spearman_metric]) \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#the model won't learn well if spearman_correlation_loss is used, but try it and see the results.\u001b[39;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# fit model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesty\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# evaluate the model\u001b[39;00m\n\u001b[32m     15\u001b[39m train_e = model.evaluate(trainX, trainy, verbose=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cpsc330arm/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cpsc330arm/lib/python3.11/site-packages/keras/src/metrics/reduction_metrics.py:41\u001b[39m, in \u001b[36mreduce_to_samplewise_values\u001b[39m\u001b[34m(values, sample_weight, reduce_fn, dtype)\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m weight_ndim > \u001b[32m1\u001b[39m:\n\u001b[32m     37\u001b[39m         sample_weight = reduce_fn(\n\u001b[32m     38\u001b[39m             sample_weight, axis=\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, weight_ndim))\n\u001b[32m     39\u001b[39m         )\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m values_ndim = \u001b[38;5;28mlen\u001b[39m(values.shape)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m values_ndim > \u001b[32m1\u001b[39m:\n\u001b[32m     43\u001b[39m     values = reduce_fn(values, axis=\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, values_ndim)))\n",
      "\u001b[31mValueError\u001b[39m: Cannot take the length of shape with unknown rank."
     ]
    }
   ],
   "source": [
    "# mlp with scaled outputs on the regression problem with custom loss and custom metric\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model using as loss: 'mean_squared_error', and as metric: spearman_metric\n",
    "model.compile(loss=spearman_correlation_loss,\n",
    "              optimizer=SGD(learning_rate=0.01, momentum=0.9),\n",
    "              metrics=[spearman_metric]) \n",
    "#the model won't learn well if spearman_correlation_loss is used, but try it and see the results.\n",
    "    \n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=1)\n",
    "# evaluate the model\n",
    "train_e = model.evaluate(trainX, trainy, verbose=1)\n",
    "test_e = model.evaluate(testX, testy, verbose=1)\n",
    "print('Train loss: %.3f, Test loss: %.3f' % (train_e[0], test_e[0])) #when using custom loss and custom metric\n",
    "print('Train metric: %.3f, Test metric: %.3f' % (train_e[1], test_e[1])) #when using custom loss and custom metric\n",
    "#plot loss during training\n",
    "pyplot.title('Loss / Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does Keras use metric functions (including custom metric functions) for anything other than reporting?\n",
    "You can use a metric function in a callback to make Keras stop training when the metric function's score\n",
    "is no longer improving.\n",
    "See:\n",
    "https://archive.md/OLvkZ\n",
    "https://archive.md/VTS87\n",
    "https://archive.md/RV8A8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cpsc330arm)",
   "language": "python",
   "name": "cpsc330arm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
