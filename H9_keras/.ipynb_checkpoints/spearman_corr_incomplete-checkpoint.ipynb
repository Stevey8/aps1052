{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the missing code (#####) to use a custom loss and custom metric function. Here you learn to use the spearman_metric function. Check the very important question at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "import keras.backend as K\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see how to calculate the spearman correlation using numpy (1a), tensors (1b) and scipy.stats.spearmanr (3).\n",
    "The results are similar. The comparison is in 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy spearman: 0.7\n",
      "tf spearman 0.7\n",
      "SpearmanrResult(correlation=0.7, pvalue=0.1881204043741873)\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "def spearman_correlation(predictions, targets):\n",
    "    if not isinstance(predictions, pd.Series):\n",
    "        predictions = pd.Series(predictions)\n",
    "    ranked_preds = predictions.rank(pct = True, method = \"first\")\n",
    "    return np.corrcoef(ranked_preds, targets)[0, 1]\n",
    "\n",
    "#2a\n",
    "def corrcoef(x, y):\n",
    "#np.corrcoef() implemented with tf primitives\n",
    "\n",
    "    mx = tf.math.reduce_mean(x)\n",
    "    my = tf.math.reduce_mean(y)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = tf.math.reduce_sum(xm * ym)\n",
    "    r_den = tf.norm(xm) * tf.norm(ym)\n",
    "    return r_num / (r_den + tf.keras.backend.epsilon())\n",
    "\n",
    "#2b\n",
    "def tf_spearman_correlation(predictions, targets):\n",
    "    ranked_preds = tf.cast(tf.argsort(tf.argsort(predictions, stable = True)), targets.dtype)\n",
    "    return corrcoef(ranked_preds, targets)\n",
    "\n",
    "targets = np.array([0.0, 0.25, 0.5, 0.75, 1.0], dtype = np.float32)\n",
    "predictions = np.random.rand(targets.shape[0])\n",
    "\n",
    "print(\"numpy spearman:\", spearman_correlation(predictions, targets))\n",
    "result = tf_spearman_correlation(tf.convert_to_tensor(predictions, dtype=tf.float32), tf.convert_to_tensor(targets, dtype=tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    scalar = result.eval()\n",
    "\n",
    "#COMPARISON\n",
    "print(\"tf spearman\", scalar)\n",
    "#3\n",
    "print (spearmanr(targets,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use tensors to program a spearman loss. Note the argsort operation in line 7, which is not differentiable. \n",
    "If you tell Keras to use this spearman_loss, it will complain about the lack of a gradient. So spearman_loss cannot be used.\n",
    "The ranking step needs to substituted by a tensor operation that is similar enough and yet differentiable not available in tf 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_loss(y_true, y_pred):\n",
    "#Generates an error due to ranking operation not being differentiable do not use\n",
    "    \"\"\"Spearman correlation coefficient\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    y = tf.cast(tf.argsort(tf.argsort(y, stable = True)), targets.dtype) #argsort is not a differentiable operation\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "\n",
    "    return  tf.constant(1.0, dtype=x.dtype) - K.square(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use tensors to program a spearman metric. Note the use of py_func (a shortcut)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "py_func is a tf wrapper for a python function. py_func returns a tensor.\n",
    "Below we use py_func to wrap around the python function spearmanr.\n",
    "This use of py_func works in my setup but it does not always work.\n",
    "If you have problems with it, \n",
    "just use the spearman_metric underneath (commented out) that uses tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_metric(y_true, y_pred):\n",
    "    \"\"\"Spearman correlation coefficient\"\"\"\n",
    "\n",
    "    r = tf.py_function(spearmanr, inp=[y_true, y_pred], Tout=tf.float32)\n",
    "    \n",
    "    return  tf.constant(1.0, dtype=y_true.dtype) - r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def spearman_metric(y_true, y_pred):\n",
    "    \"\"\"Spearman correlation coefficient\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    y = tf.cast(tf.argsort(tf.argsort(y, stable = True)), targets.dtype)\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "\n",
    "    return  tf.constant(1.0, dtype=x.dtype) - K.square(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=num_features, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainX)\n",
    "# transform training dataset\n",
    "trainX = scaler.transform(trainX)\n",
    "# transform test dataset\n",
    "testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 293us/step - loss: 1.3144 - spearman_metric: 0.5911 - val_loss: 0.6030 - val_spearman_metric: 0.2184\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.3210 - spearman_metric: 0.1517 - val_loss: 0.1839 - val_spearman_metric: 0.0691\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 106us/step - loss: 0.1476 - spearman_metric: 0.0836 - val_loss: 0.1439 - val_spearman_metric: 0.0566\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 86us/step - loss: 0.0961 - spearman_metric: 0.0605 - val_loss: 0.0969 - val_spearman_metric: 0.0364\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 91us/step - loss: 0.0704 - spearman_metric: 0.0405 - val_loss: 0.0769 - val_spearman_metric: 0.0349\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 105us/step - loss: 0.0540 - spearman_metric: 0.0378 - val_loss: 0.0645 - val_spearman_metric: 0.0305\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 89us/step - loss: 0.0462 - spearman_metric: 0.0299 - val_loss: 0.0573 - val_spearman_metric: 0.0291\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0423 - spearman_metric: 0.0301 - val_loss: 0.0461 - val_spearman_metric: 0.0233\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 90us/step - loss: 0.0339 - spearman_metric: 0.0236 - val_loss: 0.0420 - val_spearman_metric: 0.0221\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0287 - spearman_metric: 0.0246 - val_loss: 0.0373 - val_spearman_metric: 0.0198\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.0264 - spearman_metric: 0.0211 - val_loss: 0.0351 - val_spearman_metric: 0.0182\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0244 - spearman_metric: 0.0193 - val_loss: 0.0308 - val_spearman_metric: 0.0161\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0209 - spearman_metric: 0.0199 - val_loss: 0.0282 - val_spearman_metric: 0.0162\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 81us/step - loss: 0.0195 - spearman_metric: 0.0193 - val_loss: 0.0255 - val_spearman_metric: 0.0146\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0184 - spearman_metric: 0.0191 - val_loss: 0.0236 - val_spearman_metric: 0.0147\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0169 - spearman_metric: 0.0137 - val_loss: 0.0227 - val_spearman_metric: 0.0135\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 82us/step - loss: 0.0157 - spearman_metric: 0.0120 - val_loss: 0.0212 - val_spearman_metric: 0.0132\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 91us/step - loss: 0.0154 - spearman_metric: 0.0152 - val_loss: 0.0220 - val_spearman_metric: 0.0130\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0137 - spearman_metric: 0.0126 - val_loss: 0.0186 - val_spearman_metric: 0.0128\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 108us/step - loss: 0.0126 - spearman_metric: 0.0122 - val_loss: 0.0175 - val_spearman_metric: 0.0127\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0114 - spearman_metric: 0.0106 - val_loss: 0.0168 - val_spearman_metric: 0.0113\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 90us/step - loss: 0.0111 - spearman_metric: 0.0117 - val_loss: 0.0154 - val_spearman_metric: 0.0109\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 89us/step - loss: 0.0103 - spearman_metric: 0.0112 - val_loss: 0.0152 - val_spearman_metric: 0.0111\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0100 - spearman_metric: 0.0100 - val_loss: 0.0148 - val_spearman_metric: 0.0104\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 78us/step - loss: 0.0095 - spearman_metric: 0.0110 - val_loss: 0.0138 - val_spearman_metric: 0.0101\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0091 - spearman_metric: 0.0099 - val_loss: 0.0133 - val_spearman_metric: 0.0095\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 105us/step - loss: 0.0088 - spearman_metric: 0.0098 - val_loss: 0.0141 - val_spearman_metric: 0.0093\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.0088 - spearman_metric: 0.0083 - val_loss: 0.0134 - val_spearman_metric: 0.0091\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 107us/step - loss: 0.0079 - spearman_metric: 0.0098 - val_loss: 0.0121 - val_spearman_metric: 0.0091\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 83us/step - loss: 0.0079 - spearman_metric: 0.0086 - val_loss: 0.0121 - val_spearman_metric: 0.0087\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0074 - spearman_metric: 0.0066 - val_loss: 0.0117 - val_spearman_metric: 0.0084\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 81us/step - loss: 0.0075 - spearman_metric: 0.0096 - val_loss: 0.0106 - val_spearman_metric: 0.0083\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0069 - spearman_metric: 0.0073 - val_loss: 0.0109 - val_spearman_metric: 0.0078\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0070 - spearman_metric: 0.0082 - val_loss: 0.0104 - val_spearman_metric: 0.0077\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0066 - spearman_metric: 0.0075 - val_loss: 0.0097 - val_spearman_metric: 0.0075\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 75us/step - loss: 0.0062 - spearman_metric: 0.0076 - val_loss: 0.0106 - val_spearman_metric: 0.0072\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0059 - spearman_metric: 0.0064 - val_loss: 0.0093 - val_spearman_metric: 0.0070\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 109us/step - loss: 0.0057 - spearman_metric: 0.0077 - val_loss: 0.0091 - val_spearman_metric: 0.0070\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.0058 - spearman_metric: 0.0061 - val_loss: 0.0090 - val_spearman_metric: 0.0070\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0054 - spearman_metric: 0.0081 - val_loss: 0.0093 - val_spearman_metric: 0.0065\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0054 - spearman_metric: 0.0049 - val_loss: 0.0085 - val_spearman_metric: 0.0066\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0052 - spearman_metric: 0.0080 - val_loss: 0.0082 - val_spearman_metric: 0.0064\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 74us/step - loss: 0.0049 - spearman_metric: 0.0065 - val_loss: 0.0080 - val_spearman_metric: 0.0065\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 124us/step - loss: 0.0050 - spearman_metric: 0.0058 - val_loss: 0.0079 - val_spearman_metric: 0.0063\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 89us/step - loss: 0.0048 - spearman_metric: 0.0062 - val_loss: 0.0078 - val_spearman_metric: 0.0061\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 105us/step - loss: 0.0046 - spearman_metric: 0.0050 - val_loss: 0.0075 - val_spearman_metric: 0.0062\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0046 - spearman_metric: 0.0057 - val_loss: 0.0070 - val_spearman_metric: 0.0061\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0043 - spearman_metric: 0.0063 - val_loss: 0.0069 - val_spearman_metric: 0.0061\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0041 - spearman_metric: 0.0058 - val_loss: 0.0067 - val_spearman_metric: 0.0058\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0040 - spearman_metric: 0.0062 - val_loss: 0.0064 - val_spearman_metric: 0.0057\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0040 - spearman_metric: 0.0057 - val_loss: 0.0066 - val_spearman_metric: 0.0054\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0037 - spearman_metric: 0.0049 - val_loss: 0.0062 - val_spearman_metric: 0.0057\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0036 - spearman_metric: 0.0040 - val_loss: 0.0062 - val_spearman_metric: 0.0052\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0036 - spearman_metric: 0.0044 - val_loss: 0.0057 - val_spearman_metric: 0.0052\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0033 - spearman_metric: 0.0050 - val_loss: 0.0055 - val_spearman_metric: 0.0052\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0032 - spearman_metric: 0.0048 - val_loss: 0.0055 - val_spearman_metric: 0.0054\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0032 - spearman_metric: 0.0044 - val_loss: 0.0054 - val_spearman_metric: 0.0050\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0032 - spearman_metric: 0.0033 - val_loss: 0.0054 - val_spearman_metric: 0.0050\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0031 - spearman_metric: 0.0048 - val_loss: 0.0049 - val_spearman_metric: 0.0047\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0030 - spearman_metric: 0.0037 - val_loss: 0.0050 - val_spearman_metric: 0.0048\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0027 - spearman_metric: 0.0037 - val_loss: 0.0046 - val_spearman_metric: 0.0046\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0027 - spearman_metric: 0.0039 - val_loss: 0.0045 - val_spearman_metric: 0.0047\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 124us/step - loss: 0.0027 - spearman_metric: 0.0037 - val_loss: 0.0045 - val_spearman_metric: 0.0046\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 72us/step - loss: 0.0025 - spearman_metric: 0.0044 - val_loss: 0.0044 - val_spearman_metric: 0.0044\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 107us/step - loss: 0.0026 - spearman_metric: 0.0040 - val_loss: 0.0043 - val_spearman_metric: 0.0044\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.0024 - spearman_metric: 0.0041 - val_loss: 0.0041 - val_spearman_metric: 0.0043\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0023 - spearman_metric: 0.0044 - val_loss: 0.0038 - val_spearman_metric: 0.0042\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 81us/step - loss: 0.0022 - spearman_metric: 0.0034 - val_loss: 0.0038 - val_spearman_metric: 0.0042\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0022 - spearman_metric: 0.0035 - val_loss: 0.0037 - val_spearman_metric: 0.0043\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 79us/step - loss: 0.0021 - spearman_metric: 0.0048 - val_loss: 0.0040 - val_spearman_metric: 0.0040\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0021 - spearman_metric: 0.0037 - val_loss: 0.0036 - val_spearman_metric: 0.0040\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0021 - spearman_metric: 0.0039 - val_loss: 0.0036 - val_spearman_metric: 0.0038\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 79us/step - loss: 0.0020 - spearman_metric: 0.0027 - val_loss: 0.0033 - val_spearman_metric: 0.0040\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0018 - spearman_metric: 0.0032 - val_loss: 0.0033 - val_spearman_metric: 0.0039\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 75us/step - loss: 0.0018 - spearman_metric: 0.0030 - val_loss: 0.0031 - val_spearman_metric: 0.0039\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 91us/step - loss: 0.0017 - spearman_metric: 0.0032 - val_loss: 0.0030 - val_spearman_metric: 0.0036\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0017 - spearman_metric: 0.0021 - val_loss: 0.0030 - val_spearman_metric: 0.0036\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 79us/step - loss: 0.0016 - spearman_metric: 0.0026 - val_loss: 0.0030 - val_spearman_metric: 0.0036\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0016 - spearman_metric: 0.0030 - val_loss: 0.0028 - val_spearman_metric: 0.0034\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 84us/step - loss: 0.0015 - spearman_metric: 0.0035 - val_loss: 0.0027 - val_spearman_metric: 0.0035\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 90us/step - loss: 0.0014 - spearman_metric: 0.0029 - val_loss: 0.0026 - val_spearman_metric: 0.0034\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0015 - spearman_metric: 0.0031 - val_loss: 0.0024 - val_spearman_metric: 0.0034\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 77us/step - loss: 0.0014 - spearman_metric: 0.0025 - val_loss: 0.0025 - val_spearman_metric: 0.0033\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 105us/step - loss: 0.0013 - spearman_metric: 0.0020 - val_loss: 0.0023 - val_spearman_metric: 0.0032\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 81us/step - loss: 0.0013 - spearman_metric: 0.0025 - val_loss: 0.0023 - val_spearman_metric: 0.0032\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 106us/step - loss: 0.0012 - spearman_metric: 0.0023 - val_loss: 0.0022 - val_spearman_metric: 0.0030\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 79us/step - loss: 0.0012 - spearman_metric: 0.0029 - val_loss: 0.0023 - val_spearman_metric: 0.0030\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 87us/step - loss: 0.0012 - spearman_metric: 0.0031 - val_loss: 0.0020 - val_spearman_metric: 0.0029\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 109us/step - loss: 0.0011 - spearman_metric: 0.0026 - val_loss: 0.0021 - val_spearman_metric: 0.0028\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0011 - spearman_metric: 0.0021 - val_loss: 0.0019 - val_spearman_metric: 0.0029\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0010 - spearman_metric: 0.0025 - val_loss: 0.0019 - val_spearman_metric: 0.0027\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0010 - spearman_metric: 0.0022 - val_loss: 0.0019 - val_spearman_metric: 0.0028\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0011 - spearman_metric: 0.0026 - val_loss: 0.0019 - val_spearman_metric: 0.0028\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 90us/step - loss: 0.0010 - spearman_metric: 0.0029 - val_loss: 0.0017 - val_spearman_metric: 0.0026\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 9.3197e-04 - spearman_metric: 0.0020 - val_loss: 0.0016 - val_spearman_metric: 0.0026\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 9.1498e-04 - spearman_metric: 0.0026 - val_loss: 0.0016 - val_spearman_metric: 0.0027\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 8.7122e-04 - spearman_metric: 0.0022 - val_loss: 0.0016 - val_spearman_metric: 0.0027\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 90us/step - loss: 8.2085e-04 - spearman_metric: 0.0020 - val_loss: 0.0015 - val_spearman_metric: 0.0024\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 59us/step - loss: 7.9040e-04 - spearman_metric: 0.0014 - val_loss: 0.0015 - val_spearman_metric: 0.0026\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 75us/step - loss: 7.7017e-04 - spearman_metric: 0.0015 - val_loss: 0.0014 - val_spearman_metric: 0.0025\n",
      "500/500 [==============================] - 0s 37us/step\n",
      "500/500 [==============================] - 0s 65us/step\n",
      "Train loss: 0.001, Test loss: 0.001\n",
      "Train metric: 0.002, Test metric: 0.002\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mlp with scaled outputs on the regression problem with custom loss and custom metric\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model using spearman_metric\n",
    "model.compile(#####\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=1)\n",
    "# evaluate the model\n",
    "train_e = model.evaluate(trainX, trainy, verbose=1)\n",
    "test_e = model.evaluate(testX, testy, verbose=1)\n",
    "print('Train loss: %.3f, Test loss: %.3f' % (train_e[0], test_e[0])) #when using custom loss and custom metric\n",
    "print('Train metric: %.3f, Test metric: %.3f' % (train_e[1], test_e[1])) #when using custom loss and custom metric\n",
    "#print('Train loss: %.3f, Test loss: %.3f' % (train_e, test_e)) \n",
    "#plot loss during training\n",
    "pyplot.title('Loss / Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does Keras use metric functions (including custom metric functions) for anything other than reporting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
