{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the missing code (#####) to use a custom loss and custom metric function. Here you learn to use the spearman_metric function. Check the very important question at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "import keras.backend as K\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see how to calculate the spearman correlation using numpy (1a), tensors (1b) and scipy.stats.spearmanr (3).\n",
    "The results are similar. The comparison is in 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a spearman from scratch using numpy\n",
    "def spearman_correlation(predictions, targets):\n",
    "    if not isinstance(predictions, pd.Series):\n",
    "        predictions = pd.Series(predictions)\n",
    "    ranked_preds = predictions.rank(pct = True, method = \"first\")\n",
    "    return np.corrcoef(ranked_preds, targets)[0, 1]\n",
    "\n",
    "#2a spearman from scratch using tensors\n",
    "def corrcoef(x, y):\n",
    "\n",
    "    mx = tf.math.reduce_mean(x)\n",
    "    my = tf.math.reduce_mean(y)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = tf.math.reduce_sum(xm * ym)\n",
    "    r_den = tf.norm(xm) * tf.norm(ym)\n",
    "    return r_num / (r_den + tf.keras.backend.epsilon())\n",
    "\n",
    "#2b. spearman using tensors\n",
    "def tf_spearman_correlation(predictions, targets):\n",
    "    ranked_preds = tf.cast(tf.argsort(tf.argsort(predictions, stable = True)), targets.dtype)\n",
    "    return corrcoef(ranked_preds, targets)\n",
    "\n",
    "targets = np.array([0.0, 0.25, 0.5, 0.75, 1.0], dtype = np.float32)\n",
    "predictions = np.random.rand(targets.shape[0])\n",
    "\n",
    "print(\"numpy spearman:\", spearman_correlation(predictions, targets))\n",
    "result = tf_spearman_correlation(tf.convert_to_tensor(predictions, dtype=tf.float32), tf.convert_to_tensor(targets, dtype=tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    scalar = result.eval()\n",
    "\n",
    "    \n",
    "#COMPARISON\n",
    "\n",
    "print(\"tf spearman\", scalar)\n",
    "#3\n",
    "print (spearmanr(targets,predictions))  #spearman using scipy stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use tensors to program a spearman loss. Note the argsort operation in line 7, which is not differentiable. \n",
    "If you tell Keras to use this spearman_loss, it will complain about the lack of a gradient. So spearman_loss cannot be used.  The ranking step needs to substituted by a tensor operation that is similar enough and yet differentiable not available in tf 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_loss(y_true, y_pred):\n",
    "#Generates an error due to ranking operation not being differentiable do not use\n",
    "    \"\"\"Spearman correlation coefficient using tensors\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    y = tf.cast(tf.argsort(tf.argsort(y, stable = True)), targets.dtype) #argsort is not a differentiable operation\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "\n",
    "    return  tf.constant(1.0, dtype=x.dtype) - K.square(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use tensors to program a spearman metric. Note the use of py_func (a shortcut)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "py_func is a tf wrapper for a python function. py_func returns a tensor.\n",
    "Below we use py_func to wrap around the python function spearmanr.\n",
    "This use of py_func works in my setup but it does not always work.\n",
    "If you have problems with it, \n",
    "just use the spearman_metric underneath (commented out) that uses tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_metric(y_true, y_pred):\n",
    "    \"\"\"Spearman correlation coefficient using a tf wrapper for a python function\"\"\"\n",
    "\n",
    "    r = tf.py_function(spearmanr, inp=[y_true, y_pred], Tout=tf.float32)\n",
    "    \n",
    "    return  tf.constant(1.0, dtype=y_true.dtype) - r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def spearman_metric(y_true, y_pred):\n",
    "    \"\"\"Spearman correlation coefficient using tensors\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    y = tf.cast(tf.argsort(tf.argsort(y, stable = True)), targets.dtype)\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "\n",
    "    return  tf.constant(1.0, dtype=x.dtype) - K.square(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=num_features, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainX)\n",
    "# transform training dataset\n",
    "trainX = scaler.transform(trainX)\n",
    "# transform test dataset\n",
    "testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 295us/step - loss: 1.5912 - spearman_metric: 0.7500 - val_loss: 0.9573 - val_spearman_metric: 0.3452\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 116us/step - loss: 0.5155 - spearman_metric: 0.2667 - val_loss: 0.3004 - val_spearman_metric: 0.1402\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.1759 - spearman_metric: 0.1072 - val_loss: 0.1607 - val_spearman_metric: 0.0680\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 106us/step - loss: 0.1036 - spearman_metric: 0.0628 - val_loss: 0.1223 - val_spearman_metric: 0.0563\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0783 - spearman_metric: 0.0488 - val_loss: 0.1010 - val_spearman_metric: 0.0459\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0596 - spearman_metric: 0.0376 - val_loss: 0.0893 - val_spearman_metric: 0.0411\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0514 - spearman_metric: 0.0332 - val_loss: 0.0796 - val_spearman_metric: 0.0396\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0448 - spearman_metric: 0.0329 - val_loss: 0.0757 - val_spearman_metric: 0.0366\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0419 - spearman_metric: 0.0302 - val_loss: 0.0714 - val_spearman_metric: 0.0340\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 95us/step - loss: 0.0380 - spearman_metric: 0.0270 - val_loss: 0.0614 - val_spearman_metric: 0.0320\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0348 - spearman_metric: 0.0288 - val_loss: 0.0557 - val_spearman_metric: 0.0293\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0319 - spearman_metric: 0.0238 - val_loss: 0.0533 - val_spearman_metric: 0.0277\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0280 - spearman_metric: 0.0209 - val_loss: 0.0488 - val_spearman_metric: 0.0268\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 95us/step - loss: 0.0256 - spearman_metric: 0.0177 - val_loss: 0.0453 - val_spearman_metric: 0.0252\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0240 - spearman_metric: 0.0151 - val_loss: 0.0437 - val_spearman_metric: 0.0232\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0217 - spearman_metric: 0.0193 - val_loss: 0.0409 - val_spearman_metric: 0.0230\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0205 - spearman_metric: 0.0209 - val_loss: 0.0369 - val_spearman_metric: 0.0215\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 95us/step - loss: 0.0184 - spearman_metric: 0.0194 - val_loss: 0.0352 - val_spearman_metric: 0.0211\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 91us/step - loss: 0.0171 - spearman_metric: 0.0180 - val_loss: 0.0330 - val_spearman_metric: 0.0203\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0171 - spearman_metric: 0.0146 - val_loss: 0.0327 - val_spearman_metric: 0.0186\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0170 - spearman_metric: 0.0131 - val_loss: 0.0305 - val_spearman_metric: 0.0177\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0144 - spearman_metric: 0.0133 - val_loss: 0.0289 - val_spearman_metric: 0.0184\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0135 - spearman_metric: 0.0154 - val_loss: 0.0289 - val_spearman_metric: 0.0176\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0137 - spearman_metric: 0.0127 - val_loss: 0.0277 - val_spearman_metric: 0.0168\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0127 - spearman_metric: 0.0107 - val_loss: 0.0247 - val_spearman_metric: 0.0165\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0118 - spearman_metric: 0.0122 - val_loss: 0.0243 - val_spearman_metric: 0.0157\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0115 - spearman_metric: 0.0095 - val_loss: 0.0229 - val_spearman_metric: 0.0157\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 106us/step - loss: 0.0108 - spearman_metric: 0.0115 - val_loss: 0.0219 - val_spearman_metric: 0.0150\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0108 - spearman_metric: 0.0100 - val_loss: 0.0218 - val_spearman_metric: 0.0146\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0097 - spearman_metric: 0.0099 - val_loss: 0.0205 - val_spearman_metric: 0.0140\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 101us/step - loss: 0.0093 - spearman_metric: 0.0100 - val_loss: 0.0201 - val_spearman_metric: 0.0137\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0091 - spearman_metric: 0.0103 - val_loss: 0.0194 - val_spearman_metric: 0.0136\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0088 - spearman_metric: 0.0098 - val_loss: 0.0189 - val_spearman_metric: 0.0131\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0087 - spearman_metric: 0.0081 - val_loss: 0.0186 - val_spearman_metric: 0.0127\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0081 - spearman_metric: 0.0102 - val_loss: 0.0178 - val_spearman_metric: 0.0128\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0078 - spearman_metric: 0.0100 - val_loss: 0.0185 - val_spearman_metric: 0.0121\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0082 - spearman_metric: 0.0081 - val_loss: 0.0174 - val_spearman_metric: 0.0123\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0076 - spearman_metric: 0.0090 - val_loss: 0.0170 - val_spearman_metric: 0.0124\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0073 - spearman_metric: 0.0092 - val_loss: 0.0162 - val_spearman_metric: 0.0118\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0072 - spearman_metric: 0.0094 - val_loss: 0.0161 - val_spearman_metric: 0.0114\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0068 - spearman_metric: 0.0088 - val_loss: 0.0157 - val_spearman_metric: 0.0117\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0069 - spearman_metric: 0.0068 - val_loss: 0.0149 - val_spearman_metric: 0.0113\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0067 - spearman_metric: 0.0092 - val_loss: 0.0154 - val_spearman_metric: 0.0112\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0065 - spearman_metric: 0.0070 - val_loss: 0.0145 - val_spearman_metric: 0.0108\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0062 - spearman_metric: 0.0080 - val_loss: 0.0146 - val_spearman_metric: 0.0115\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0065 - spearman_metric: 0.0082 - val_loss: 0.0151 - val_spearman_metric: 0.0107\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0057 - spearman_metric: 0.0068 - val_loss: 0.0134 - val_spearman_metric: 0.0104\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0056 - spearman_metric: 0.0081 - val_loss: 0.0132 - val_spearman_metric: 0.0105\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0054 - spearman_metric: 0.0065 - val_loss: 0.0135 - val_spearman_metric: 0.0101\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0055 - spearman_metric: 0.0065 - val_loss: 0.0127 - val_spearman_metric: 0.0103\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0052 - spearman_metric: 0.0067 - val_loss: 0.0125 - val_spearman_metric: 0.0102\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0054 - spearman_metric: 0.0080 - val_loss: 0.0126 - val_spearman_metric: 0.0102\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0050 - spearman_metric: 0.0054 - val_loss: 0.0120 - val_spearman_metric: 0.0097\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0049 - spearman_metric: 0.0065 - val_loss: 0.0120 - val_spearman_metric: 0.0100\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0047 - spearman_metric: 0.0073 - val_loss: 0.0116 - val_spearman_metric: 0.0094\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0046 - spearman_metric: 0.0060 - val_loss: 0.0114 - val_spearman_metric: 0.0093\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0045 - spearman_metric: 0.0069 - val_loss: 0.0112 - val_spearman_metric: 0.0094\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0043 - spearman_metric: 0.0066 - val_loss: 0.0112 - val_spearman_metric: 0.0093\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0043 - spearman_metric: 0.0063 - val_loss: 0.0109 - val_spearman_metric: 0.0092\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0042 - spearman_metric: 0.0059 - val_loss: 0.0107 - val_spearman_metric: 0.0092\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0043 - spearman_metric: 0.0053 - val_loss: 0.0105 - val_spearman_metric: 0.0090\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0042 - spearman_metric: 0.0044 - val_loss: 0.0106 - val_spearman_metric: 0.0091\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0040 - spearman_metric: 0.0056 - val_loss: 0.0104 - val_spearman_metric: 0.0089\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0039 - spearman_metric: 0.0052 - val_loss: 0.0101 - val_spearman_metric: 0.0090\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0039 - spearman_metric: 0.0063 - val_loss: 0.0098 - val_spearman_metric: 0.0085\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0038 - spearman_metric: 0.0059 - val_loss: 0.0098 - val_spearman_metric: 0.0087\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0038 - spearman_metric: 0.0053 - val_loss: 0.0097 - val_spearman_metric: 0.0083\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0036 - spearman_metric: 0.0046 - val_loss: 0.0096 - val_spearman_metric: 0.0086\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0037 - spearman_metric: 0.0059 - val_loss: 0.0093 - val_spearman_metric: 0.0081\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0038 - spearman_metric: 0.0046 - val_loss: 0.0094 - val_spearman_metric: 0.0080\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0036 - spearman_metric: 0.0054 - val_loss: 0.0090 - val_spearman_metric: 0.0080\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0037 - spearman_metric: 0.0047 - val_loss: 0.0091 - val_spearman_metric: 0.0082\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0034 - spearman_metric: 0.0047 - val_loss: 0.0089 - val_spearman_metric: 0.0080\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0033 - spearman_metric: 0.0041 - val_loss: 0.0085 - val_spearman_metric: 0.0079\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0032 - spearman_metric: 0.0051 - val_loss: 0.0085 - val_spearman_metric: 0.0077\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 104us/step - loss: 0.0032 - spearman_metric: 0.0047 - val_loss: 0.0085 - val_spearman_metric: 0.0078\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 164us/step - loss: 0.0031 - spearman_metric: 0.0044 - val_loss: 0.0083 - val_spearman_metric: 0.0080\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0033 - spearman_metric: 0.0048 - val_loss: 0.0080 - val_spearman_metric: 0.0079\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0033 - spearman_metric: 0.0046 - val_loss: 0.0082 - val_spearman_metric: 0.0076\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0034 - spearman_metric: 0.0046 - val_loss: 0.0078 - val_spearman_metric: 0.0077\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0031 - spearman_metric: 0.0050 - val_loss: 0.0077 - val_spearman_metric: 0.0078\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0030 - spearman_metric: 0.0040 - val_loss: 0.0076 - val_spearman_metric: 0.0075\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0029 - spearman_metric: 0.0040 - val_loss: 0.0077 - val_spearman_metric: 0.0076\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0029 - spearman_metric: 0.0048 - val_loss: 0.0074 - val_spearman_metric: 0.0074\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0028 - spearman_metric: 0.0047 - val_loss: 0.0073 - val_spearman_metric: 0.0074\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0027 - spearman_metric: 0.0050 - val_loss: 0.0072 - val_spearman_metric: 0.0072\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0027 - spearman_metric: 0.0051 - val_loss: 0.0071 - val_spearman_metric: 0.0073\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0026 - spearman_metric: 0.0037 - val_loss: 0.0069 - val_spearman_metric: 0.0067\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0026 - spearman_metric: 0.0043 - val_loss: 0.0068 - val_spearman_metric: 0.0071\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0026 - spearman_metric: 0.0052 - val_loss: 0.0069 - val_spearman_metric: 0.0067\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0025 - spearman_metric: 0.0047 - val_loss: 0.0065 - val_spearman_metric: 0.0067\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0025 - spearman_metric: 0.0042 - val_loss: 0.0065 - val_spearman_metric: 0.0067\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0025 - spearman_metric: 0.0048 - val_loss: 0.0065 - val_spearman_metric: 0.0065\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0024 - spearman_metric: 0.0033 - val_loss: 0.0063 - val_spearman_metric: 0.0066\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0025 - spearman_metric: 0.0034 - val_loss: 0.0065 - val_spearman_metric: 0.0065\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0026 - spearman_metric: 0.0041 - val_loss: 0.0064 - val_spearman_metric: 0.0065\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0023 - spearman_metric: 0.0035 - val_loss: 0.0060 - val_spearman_metric: 0.0064\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0023 - spearman_metric: 0.0064 - val_loss: 0.0060 - val_spearman_metric: 0.0063\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0023 - spearman_metric: 0.0047 - val_loss: 0.0059 - val_spearman_metric: 0.0063\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0021 - spearman_metric: 0.0034 - val_loss: 0.0057 - val_spearman_metric: 0.0061\n",
      "500/500 [==============================] - 0s 46us/step\n",
      "500/500 [==============================] - 0s 48us/step\n",
      "Train loss: 0.002, Test loss: 0.006\n",
      "Train metric: 0.003, Test metric: 0.006\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mlp with scaled outputs on the regression problem with custom loss and custom metric\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model using spearman_metric\n",
    "#model.compile(loss=spearman_loss, optimizer=SGD(lr=0.01, momentum=0.9), metrics=[spearman_metric]) #no gradient for spearman_loss, cannot use\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9), metrics=[spearman_metric])\n",
    "#model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9))\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=1)\n",
    "# evaluate the model\n",
    "train_e = model.evaluate(trainX, trainy, verbose=1)\n",
    "test_e = model.evaluate(testX, testy, verbose=1)\n",
    "print('Train loss: %.3f, Test loss: %.3f' % (train_e[0], test_e[0])) #when using custom loss and custom metric\n",
    "print('Train metric: %.3f, Test metric: %.3f' % (train_e[1], test_e[1])) #when using custom loss and custom metric\n",
    "#print('Train loss: %.3f, Test loss: %.3f' % (train_e, test_e)) \n",
    "#plot loss during training\n",
    "pyplot.title('Loss / Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does Keras use metric functions (including custom metric functions) for anything other than reporting?\n",
    "You can use a metric function in a callback to make Keras stop training when the metric function's score\n",
    "is no longer improving.\n",
    "See:\n",
    "https://archive.md/OLvkZ\n",
    "https://archive.md/VTS87\n",
    "https://archive.md/RV8A8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
