{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "import tensorflow.keras.backend as K\n",
    "import altair as alt\n",
    "from keras_hist_graph import plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.enable_eager_execution()\n",
    "#%xmode Verbose\n",
    "#%xmode Context\n",
    "\n",
    "def t(a):\n",
    "  \"\"\"For testing: generate a float64 tensor from anything.\"\"\"\n",
    "  return tf.constant(a, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.]\n"
     ]
    }
   ],
   "source": [
    "def tmean(x, axis=-1):\n",
    "  \"\"\"Arithmetic mean of a tensor over some axis, default last.\"\"\"\n",
    "  x = tf.convert_to_tensor(x)\n",
    "  sum = tf.reduce_sum(x, axis=axis)\n",
    "  n = tf.cast(tf.shape(x)[axis], x.dtype)\n",
    "  return sum / n\n",
    "\n",
    "print(tmean(t([[1.0],[2.0],[3.0]]), axis=-2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5]\n",
      "[0.]\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "def correlationMetric(x, y, axis=-2):\n",
    "  \"\"\"Metric returning the Pearson correlation coefficient of two tensors over some axis, default -2.\"\"\"\n",
    "  x = tf.convert_to_tensor(x)\n",
    "  #y = math_ops.cast(y, x.dtype)\n",
    "  y = K.cast(y, x.dtype)\n",
    "  n = tf.cast(tf.shape(x)[axis], x.dtype)\n",
    "  xsum = tf.reduce_sum(x, axis=axis)\n",
    "  ysum = tf.reduce_sum(y, axis=axis)\n",
    "  xmean = xsum / n\n",
    "  ymean = ysum / n\n",
    "  xvar = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n",
    "  yvar = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n",
    "  cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n",
    "  corr = cov / tf.sqrt(xvar * yvar)\n",
    "  return tf.constant(1.0, dtype=x.dtype) - corr\n",
    "\n",
    "print(correlationMetric(tf.constant([[0.0, 1.0, 2.0]]), tf.constant([[1.0, 3.0, 2.0]]), axis=-1).numpy())\n",
    "print(correlationMetric(tf.constant([[0.0, 2.0, 1.0]]), tf.constant([[1.0, 3.0, 2.0]]), axis=-1).numpy())\n",
    "print(correlationMetric(tf.constant([[0.0], [2.0], [1.0]]), tf.constant([[1.0], [3.0], [2.0]]), axis=-2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlationLoss(x,y, axis=-2):\n",
    "  \"\"\"Loss function that maximizes the pearson correlation coefficient between the predicted values and the labels,\n",
    "  while trying to have the same mean and variance\"\"\"\n",
    "  x = tf.convert_to_tensor(x)\n",
    "  #y = math_ops.cast(y, x.dtype)\n",
    "  y = K.cast(y, x.dtype)\n",
    "  n = tf.cast(tf.shape(x)[axis], x.dtype)\n",
    "  xsum = tf.reduce_sum(x, axis=axis)\n",
    "  ysum = tf.reduce_sum(y, axis=axis)\n",
    "  xmean = xsum / n\n",
    "  ymean = ysum / n\n",
    "  xsqsum = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n",
    "  ysqsum = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n",
    "  cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n",
    "  corr = cov / tf.sqrt(xsqsum * ysqsum)\n",
    "  # absdif = tmean(tf.abs(x - y), axis=axis) / tf.sqrt(yvar)\n",
    "  sqdif = tf.reduce_sum(tf.math.squared_difference(x, y), axis=axis) / n / tf.sqrt(ysqsum / n)\n",
    "  # meandif = tf.abs(xmean - ymean) / tf.abs(ymean)\n",
    "  # vardif = tf.abs(xvar - yvar) / yvar\n",
    "  # return tf.convert_to_tensor( K.mean(tf.constant(1.0, dtype=x.dtype) - corr + (meandif * 0.01) + (vardif * 0.01)) , dtype=tf.float32 )\n",
    "  return tf.convert_to_tensor( K.mean(tf.constant(1.0, dtype=x.dtype) - corr + (0.01 * sqdif)) , dtype=tf.float32 )\n",
    "\n",
    "#t1,t2 = tf.constant([[0.0], [3.0], [2.0]]), tf.constant([[0.0], [1.0], [3.0]])\n",
    "#print(correlationLoss(t1,t2))\n",
    "#print(correlationMetric(t1,t2))\n",
    "#del t1,t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 10240\n",
    "epochs = 100\n",
    "steps = 1024\n",
    "batchsize = 128\n",
    "validationsamples = samples // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240, 2) (10240, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_d</th>\n",
       "      <th>r_d</th>\n",
       "      <th>y_g</th>\n",
       "      <th>z_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>-0.503342</td>\n",
       "      <td>0.175817</td>\n",
       "      <td>1.195424</td>\n",
       "      <td>2.906099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6344</th>\n",
       "      <td>-0.129723</td>\n",
       "      <td>-1.355488</td>\n",
       "      <td>1.167542</td>\n",
       "      <td>3.160342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>-0.272807</td>\n",
       "      <td>0.327825</td>\n",
       "      <td>0.477716</td>\n",
       "      <td>2.909321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x_d       r_d       y_g       z_g\n",
       "8528 -0.503342  0.175817  1.195424  2.906099\n",
       "6344 -0.129723 -1.355488  1.167542  3.160342\n",
       "4318 -0.272807  0.327825  0.477716  2.909321"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame( np.random.randn(samples,2), columns=['x_d', 'r_d'] ).sample(frac=1.0)\n",
    "data['y_g'] = data.x_d * data.x_d + 1\n",
    "data.y_g = data.y_g + np.random.randn(samples) * ( np.cos(3*data.x_d) ) * 0.5\n",
    "data['z_g'] = data.x_d * data.r_d + 3\n",
    "data.z_g = data.z_g + np.random.randn(samples) * data.x_d * data.r_d * 0.1\n",
    "\n",
    "train_data = data.filter(regex='_d').to_numpy()\n",
    "train_labels = data.filter(regex='_g').to_numpy()\n",
    "print(train_data.shape, train_labels.shape)\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "traindataset = traindataset.shuffle(samples)\n",
    "\n",
    "validationdataset = traindataset.take(validationsamples)\n",
    "traindataset = traindataset.skip(validationsamples)\n",
    "\n",
    "traindataset = traindataset.repeat().batch(batchsize, drop_remainder=True)\n",
    "validationdataset = validationdataset.repeat().batch(batchsize, drop_remainder=True)\n",
    "# traindataset.make_one_shot_iterator().get_next()\n",
    "# validationdataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.5230 - correlationLoss: 1.5230 - correlationMetric: 1.1138 - mse: 7.6104 - mae: 2.4618\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (128, 64)                 192       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (128, 32)                 2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (128, 2)                  66        \n",
      "=================================================================\n",
      "Total params: 2,338\n",
      "Trainable params: 2,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loss = tf.losses.mean_squared_error\n",
    "loss = correlationLoss\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.softsign))\n",
    "model.add(tf.keras.layers.Dense(32, activation=tf.nn.softsign))\n",
    "model.add(tf.keras.layers.Dense(2))\n",
    "# just a linear transformation that makes it easy to scale / shift the prediction right\n",
    "# model.add(tf.keras.layers.Dense(2))\n",
    "model.compile(loss=loss , optimizer='adam', metrics=[loss, correlationMetric, \"mse\", \"mae\"])\n",
    "\n",
    "model.fit(traindataset, steps_per_epoch=1, epochs=1) # this initializes the input_shape\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.2722 - correlationLoss: 0.2722 - correlationMetric: 0.2132 - mse: 2.7427 - mae: 1.1072 - val_loss: 0.0528 - val_correlationLoss: 0.0528 - val_correlationMetric: 0.0295 - val_mse: 1.0357 - val_mae: 0.5842\n",
      "Epoch 2/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0373 - correlationLoss: 0.0373 - correlationMetric: 0.0247 - mse: 0.6398 - mae: 0.4909 - val_loss: 0.0300 - val_correlationLoss: 0.0300 - val_correlationMetric: 0.0222 - val_mse: 0.4800 - val_mae: 0.4371\n",
      "Epoch 3/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0281 - correlationLoss: 0.0281 - correlationMetric: 0.0223 - mse: 0.4019 - mae: 0.3949 - val_loss: 0.0250 - val_correlationLoss: 0.0250 - val_correlationMetric: 0.0212 - val_mse: 0.2889 - val_mae: 0.3623\n",
      "Epoch 4/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0244 - correlationLoss: 0.0244 - correlationMetric: 0.0212 - mse: 0.2682 - mae: 0.3253 - val_loss: 0.0250 - val_correlationLoss: 0.0250 - val_correlationMetric: 0.0221 - val_mse: 0.2646 - val_mae: 0.3107\n",
      "Epoch 5/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0222 - correlationLoss: 0.0222 - correlationMetric: 0.0204 - mse: 0.1792 - mae: 0.2677 - val_loss: 0.0229 - val_correlationLoss: 0.0229 - val_correlationMetric: 0.0215 - val_mse: 0.1497 - val_mae: 0.2352\n",
      "Epoch 6/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0212 - correlationLoss: 0.0212 - correlationMetric: 0.0200 - mse: 0.1289 - mae: 0.2273 - val_loss: 0.0226 - val_correlationLoss: 0.0226 - val_correlationMetric: 0.0216 - val_mse: 0.0999 - val_mae: 0.2034\n",
      "Epoch 7/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0207 - correlationLoss: 0.0207 - correlationMetric: 0.0198 - mse: 0.1037 - mae: 0.2035 - val_loss: 0.0199 - val_correlationLoss: 0.0199 - val_correlationMetric: 0.0191 - val_mse: 0.0863 - val_mae: 0.1873\n",
      "Epoch 8/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0201 - correlationLoss: 0.0201 - correlationMetric: 0.0194 - mse: 0.0869 - mae: 0.1850 - val_loss: 0.0194 - val_correlationLoss: 0.0194 - val_correlationMetric: 0.0187 - val_mse: 0.0898 - val_mae: 0.1891\n",
      "Epoch 9/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0199 - correlationLoss: 0.0199 - correlationMetric: 0.0192 - mse: 0.0795 - mae: 0.1771 - val_loss: 0.0187 - val_correlationLoss: 0.0187 - val_correlationMetric: 0.0181 - val_mse: 0.0714 - val_mae: 0.1629\n",
      "Epoch 10/100\n",
      "1024/1024 [==============================] - 2s 1ms/step - loss: 0.0195 - correlationLoss: 0.0195 - correlationMetric: 0.0189 - mse: 0.0747 - mae: 0.1708 - val_loss: 0.0175 - val_correlationLoss: 0.0175 - val_correlationMetric: 0.0169 - val_mse: 0.0774 - val_mae: 0.1650\n",
      "Epoch 11/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0195 - correlationLoss: 0.0195 - correlationMetric: 0.0190 - mse: 0.0731 - mae: 0.1696 - val_loss: 0.0179 - val_correlationLoss: 0.0179 - val_correlationMetric: 0.0174 - val_mse: 0.0734 - val_mae: 0.1751\n",
      "Epoch 12/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0195 - correlationLoss: 0.0195 - correlationMetric: 0.0189 - mse: 0.0716 - mae: 0.1662 - val_loss: 0.0231 - val_correlationLoss: 0.0231 - val_correlationMetric: 0.0225 - val_mse: 0.0707 - val_mae: 0.1678\n",
      "Epoch 13/100\n",
      "1024/1024 [==============================] - 2s 1ms/step - loss: 0.0196 - correlationLoss: 0.0196 - correlationMetric: 0.0191 - mse: 0.0712 - mae: 0.1667 - val_loss: 0.0159 - val_correlationLoss: 0.0159 - val_correlationMetric: 0.0154 - val_mse: 0.0700 - val_mae: 0.1693\n",
      "Epoch 14/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0193 - correlationLoss: 0.0193 - correlationMetric: 0.0188 - mse: 0.0706 - mae: 0.1658 - val_loss: 0.0171 - val_correlationLoss: 0.0171 - val_correlationMetric: 0.0166 - val_mse: 0.0677 - val_mae: 0.1735\n",
      "Epoch 15/100\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.0194 - correlationLoss: 0.0194 - correlationMetric: 0.0189 - mse: 0.0710 - mae: 0.1666 - val_loss: 0.0187 - val_correlationLoss: 0.0187 - val_correlationMetric: 0.0181 - val_mse: 0.0690 - val_mae: 0.1643\n",
      "Epoch 16/100\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0704 - mae: 0.1656 - val_loss: 0.0186 - val_correlationLoss: 0.0186 - val_correlationMetric: 0.0181 - val_mse: 0.0692 - val_mae: 0.1675\n",
      "Epoch 17/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0194 - correlationLoss: 0.0194 - correlationMetric: 0.0188 - mse: 0.0701 - mae: 0.1649 - val_loss: 0.0285 - val_correlationLoss: 0.0285 - val_correlationMetric: 0.0279 - val_mse: 0.0791 - val_mae: 0.1662\n",
      "Epoch 18/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0193 - correlationLoss: 0.0193 - correlationMetric: 0.0188 - mse: 0.0702 - mae: 0.1651 - val_loss: 0.0197 - val_correlationLoss: 0.0197 - val_correlationMetric: 0.0191 - val_mse: 0.0761 - val_mae: 0.1783\n",
      "Epoch 19/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0193 - correlationLoss: 0.0193 - correlationMetric: 0.0187 - mse: 0.0704 - mae: 0.1653 - val_loss: 0.0226 - val_correlationLoss: 0.0226 - val_correlationMetric: 0.0221 - val_mse: 0.0689 - val_mae: 0.1575\n",
      "Epoch 20/100\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0704 - mae: 0.1648 - val_loss: 0.0186 - val_correlationLoss: 0.0186 - val_correlationMetric: 0.0181 - val_mse: 0.0661 - val_mae: 0.1549\n",
      "Epoch 21/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0699 - mae: 0.1640 - val_loss: 0.0194 - val_correlationLoss: 0.0194 - val_correlationMetric: 0.0189 - val_mse: 0.0677 - val_mae: 0.1613\n",
      "Epoch 22/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0704 - mae: 0.1651 - val_loss: 0.0226 - val_correlationLoss: 0.0226 - val_correlationMetric: 0.0220 - val_mse: 0.0684 - val_mae: 0.1615\n",
      "Epoch 23/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0193 - correlationLoss: 0.0193 - correlationMetric: 0.0188 - mse: 0.0700 - mae: 0.1642 - val_loss: 0.0198 - val_correlationLoss: 0.0198 - val_correlationMetric: 0.0193 - val_mse: 0.0698 - val_mae: 0.1666\n",
      "Epoch 24/100\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0704 - mae: 0.1664 - val_loss: 0.0185 - val_correlationLoss: 0.0185 - val_correlationMetric: 0.0180 - val_mse: 0.0744 - val_mae: 0.1628\n",
      "Epoch 25/100\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0698 - mae: 0.1647 - val_loss: 0.0223 - val_correlationLoss: 0.0223 - val_correlationMetric: 0.0217 - val_mse: 0.0800 - val_mae: 0.1744\n",
      "Epoch 26/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0702 - mae: 0.1647 - val_loss: 0.0185 - val_correlationLoss: 0.0185 - val_correlationMetric: 0.0180 - val_mse: 0.0668 - val_mae: 0.1564\n",
      "Epoch 27/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0700 - mae: 0.1646 - val_loss: 0.0225 - val_correlationLoss: 0.0225 - val_correlationMetric: 0.0220 - val_mse: 0.0701 - val_mae: 0.1581\n",
      "Epoch 28/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0193 - correlationLoss: 0.0193 - correlationMetric: 0.0188 - mse: 0.0701 - mae: 0.1639 - val_loss: 0.0178 - val_correlationLoss: 0.0178 - val_correlationMetric: 0.0173 - val_mse: 0.0682 - val_mae: 0.1632\n",
      "Epoch 29/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0701 - mae: 0.1645 - val_loss: 0.0238 - val_correlationLoss: 0.0238 - val_correlationMetric: 0.0232 - val_mse: 0.0705 - val_mae: 0.1631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0700 - mae: 0.1639 - val_loss: 0.0209 - val_correlationLoss: 0.0209 - val_correlationMetric: 0.0204 - val_mse: 0.0679 - val_mae: 0.1536\n",
      "Epoch 31/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0701 - mae: 0.1651 - val_loss: 0.0210 - val_correlationLoss: 0.0210 - val_correlationMetric: 0.0205 - val_mse: 0.0682 - val_mae: 0.1582\n",
      "Epoch 32/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0702 - mae: 0.1647 - val_loss: 0.0245 - val_correlationLoss: 0.0245 - val_correlationMetric: 0.0239 - val_mse: 0.0761 - val_mae: 0.1732\n",
      "Epoch 33/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0703 - mae: 0.1661 - val_loss: 0.0200 - val_correlationLoss: 0.0200 - val_correlationMetric: 0.0195 - val_mse: 0.0680 - val_mae: 0.1757\n",
      "Epoch 34/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0193 - correlationLoss: 0.0193 - correlationMetric: 0.0188 - mse: 0.0703 - mae: 0.1655 - val_loss: 0.0146 - val_correlationLoss: 0.0146 - val_correlationMetric: 0.0141 - val_mse: 0.0656 - val_mae: 0.1587\n",
      "Epoch 35/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0193 - correlationLoss: 0.0193 - correlationMetric: 0.0188 - mse: 0.0700 - mae: 0.1642 - val_loss: 0.0188 - val_correlationLoss: 0.0188 - val_correlationMetric: 0.0183 - val_mse: 0.0686 - val_mae: 0.1624\n",
      "Epoch 36/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0705 - mae: 0.1647 - val_loss: 0.0205 - val_correlationLoss: 0.0205 - val_correlationMetric: 0.0199 - val_mse: 0.0694 - val_mae: 0.1736\n",
      "Epoch 37/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0699 - mae: 0.1633 - val_loss: 0.0178 - val_correlationLoss: 0.0178 - val_correlationMetric: 0.0173 - val_mse: 0.0655 - val_mae: 0.1591\n",
      "Epoch 38/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0700 - mae: 0.1641 - val_loss: 0.0177 - val_correlationLoss: 0.0177 - val_correlationMetric: 0.0172 - val_mse: 0.0749 - val_mae: 0.1629\n",
      "Epoch 39/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0702 - mae: 0.1653 - val_loss: 0.0203 - val_correlationLoss: 0.0203 - val_correlationMetric: 0.0198 - val_mse: 0.0717 - val_mae: 0.1768\n",
      "Epoch 40/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0699 - mae: 0.1644 - val_loss: 0.0200 - val_correlationLoss: 0.0200 - val_correlationMetric: 0.0194 - val_mse: 0.0652 - val_mae: 0.1491\n",
      "Epoch 41/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0701 - mae: 0.1637 - val_loss: 0.0190 - val_correlationLoss: 0.0190 - val_correlationMetric: 0.0185 - val_mse: 0.0680 - val_mae: 0.1619\n",
      "Epoch 42/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0702 - mae: 0.1656 - val_loss: 0.0161 - val_correlationLoss: 0.0161 - val_correlationMetric: 0.0157 - val_mse: 0.0643 - val_mae: 0.1630\n",
      "Epoch 43/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0194 - correlationLoss: 0.0194 - correlationMetric: 0.0188 - mse: 0.0703 - mae: 0.1638 - val_loss: 0.0214 - val_correlationLoss: 0.0214 - val_correlationMetric: 0.0209 - val_mse: 0.0713 - val_mae: 0.1685\n",
      "Epoch 44/100\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0699 - mae: 0.1633 - val_loss: 0.0199 - val_correlationLoss: 0.0199 - val_correlationMetric: 0.0194 - val_mse: 0.0735 - val_mae: 0.1637\n",
      "Epoch 45/100\n",
      "1024/1024 [==============================] - 2s 1ms/step - loss: 0.0194 - correlationLoss: 0.0194 - correlationMetric: 0.0189 - mse: 0.0702 - mae: 0.1646 - val_loss: 0.0174 - val_correlationLoss: 0.0174 - val_correlationMetric: 0.0169 - val_mse: 0.0699 - val_mae: 0.1581\n",
      "Epoch 46/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0700 - mae: 0.1639 - val_loss: 0.0175 - val_correlationLoss: 0.0175 - val_correlationMetric: 0.0170 - val_mse: 0.0702 - val_mae: 0.1754\n",
      "Epoch 47/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0704 - mae: 0.1659 - val_loss: 0.0212 - val_correlationLoss: 0.0212 - val_correlationMetric: 0.0207 - val_mse: 0.0686 - val_mae: 0.1776193 - correlationLoss: 0.0193 - correlationMetric: 0.0188 - mse: 0.07\n",
      "Epoch 48/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0701 - mae: 0.1643 - val_loss: 0.0175 - val_correlationLoss: 0.0175 - val_correlationMetric: 0.0170 - val_mse: 0.0758 - val_mae: 0.1726\n",
      "Epoch 49/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0697 - mae: 0.1636 - val_loss: 0.0218 - val_correlationLoss: 0.0218 - val_correlationMetric: 0.0212 - val_mse: 0.0697 - val_mae: 0.1629\n",
      "Epoch 50/100\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0701 - mae: 0.1641 - val_loss: 0.0229 - val_correlationLoss: 0.0229 - val_correlationMetric: 0.0223 - val_mse: 0.0722 - val_mae: 0.1691\n",
      "Epoch 51/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0698 - mae: 0.1635 - val_loss: 0.0183 - val_correlationLoss: 0.0183 - val_correlationMetric: 0.0178 - val_mse: 0.0677 - val_mae: 0.1605\n",
      "Epoch 52/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0700 - mae: 0.1650 - val_loss: 0.0179 - val_correlationLoss: 0.0179 - val_correlationMetric: 0.0175 - val_mse: 0.0689 - val_mae: 0.1610\n",
      "Epoch 53/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0699 - mae: 0.1633 - val_loss: 0.0172 - val_correlationLoss: 0.0172 - val_correlationMetric: 0.0167 - val_mse: 0.0688 - val_mae: 0.1599\n",
      "Epoch 54/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0699 - mae: 0.1645 - val_loss: 0.0177 - val_correlationLoss: 0.0177 - val_correlationMetric: 0.0172 - val_mse: 0.0707 - val_mae: 0.1618\n",
      "Epoch 55/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0698 - mae: 0.1643 - val_loss: 0.0164 - val_correlationLoss: 0.0164 - val_correlationMetric: 0.0159 - val_mse: 0.0659 - val_mae: 0.1635\n",
      "Epoch 56/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0193 - correlationLoss: 0.0193 - correlationMetric: 0.0188 - mse: 0.0699 - mae: 0.1636 - val_loss: 0.0178 - val_correlationLoss: 0.0178 - val_correlationMetric: 0.0173 - val_mse: 0.0704 - val_mae: 0.1597\n",
      "Epoch 57/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0185 - mse: 0.0699 - mae: 0.1640 - val_loss: 0.0228 - val_correlationLoss: 0.0228 - val_correlationMetric: 0.0222 - val_mse: 0.0797 - val_mae: 0.1700\n",
      "Epoch 58/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0700 - mae: 0.1642 - val_loss: 0.0186 - val_correlationLoss: 0.0186 - val_correlationMetric: 0.0181 - val_mse: 0.0679 - val_mae: 0.1542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0703 - mae: 0.1650 - val_loss: 0.0183 - val_correlationLoss: 0.0183 - val_correlationMetric: 0.0177 - val_mse: 0.0740 - val_mae: 0.1610\n",
      "Epoch 60/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0193 - correlationLoss: 0.0193 - correlationMetric: 0.0188 - mse: 0.0702 - mae: 0.1646 - val_loss: 0.0181 - val_correlationLoss: 0.0181 - val_correlationMetric: 0.0177 - val_mse: 0.0688 - val_mae: 0.1593\n",
      "Epoch 61/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0700 - mae: 0.1641 - val_loss: 0.0193 - val_correlationLoss: 0.0193 - val_correlationMetric: 0.0188 - val_mse: 0.0667 - val_mae: 0.1609\n",
      "Epoch 62/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0699 - mae: 0.1632 - val_loss: 0.0171 - val_correlationLoss: 0.0171 - val_correlationMetric: 0.0167 - val_mse: 0.0695 - val_mae: 0.1587\n",
      "Epoch 63/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0699 - mae: 0.1636 - val_loss: 0.0200 - val_correlationLoss: 0.0200 - val_correlationMetric: 0.0195 - val_mse: 0.0717 - val_mae: 0.1683\n",
      "Epoch 64/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0700 - mae: 0.1635 - val_loss: 0.0180 - val_correlationLoss: 0.0180 - val_correlationMetric: 0.0175 - val_mse: 0.0681 - val_mae: 0.1587\n",
      "Epoch 65/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0186 - mse: 0.0699 - mae: 0.1639 - val_loss: 0.0187 - val_correlationLoss: 0.0187 - val_correlationMetric: 0.0182 - val_mse: 0.0668 - val_mae: 0.1620\n",
      "Epoch 66/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0697 - mae: 0.1634 - val_loss: 0.0161 - val_correlationLoss: 0.0161 - val_correlationMetric: 0.0156 - val_mse: 0.0664 - val_mae: 0.1605\n",
      "Epoch 67/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0698 - mae: 0.1639 - val_loss: 0.0177 - val_correlationLoss: 0.0177 - val_correlationMetric: 0.0173 - val_mse: 0.0658 - val_mae: 0.1605\n",
      "Epoch 68/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0186 - mse: 0.0698 - mae: 0.1640 - val_loss: 0.0176 - val_correlationLoss: 0.0176 - val_correlationMetric: 0.0172 - val_mse: 0.0738 - val_mae: 0.1669\n",
      "Epoch 69/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0699 - mae: 0.1635 - val_loss: 0.0179 - val_correlationLoss: 0.0179 - val_correlationMetric: 0.0174 - val_mse: 0.0742 - val_mae: 0.1757\n",
      "Epoch 70/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0696 - mae: 0.1628 - val_loss: 0.0201 - val_correlationLoss: 0.0201 - val_correlationMetric: 0.0196 - val_mse: 0.0673 - val_mae: 0.1578\n",
      "Epoch 71/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0700 - mae: 0.1645 - val_loss: 0.0191 - val_correlationLoss: 0.0191 - val_correlationMetric: 0.0185 - val_mse: 0.0747 - val_mae: 0.1679\n",
      "Epoch 72/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0698 - mae: 0.1633 - val_loss: 0.0172 - val_correlationLoss: 0.0172 - val_correlationMetric: 0.0167 - val_mse: 0.0658 - val_mae: 0.1582\n",
      "Epoch 73/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0697 - mae: 0.1630 - val_loss: 0.0180 - val_correlationLoss: 0.0180 - val_correlationMetric: 0.0175 - val_mse: 0.0691 - val_mae: 0.1619\n",
      "Epoch 74/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0698 - mae: 0.1642 - val_loss: 0.0192 - val_correlationLoss: 0.0192 - val_correlationMetric: 0.0186 - val_mse: 0.0766 - val_mae: 0.1835\n",
      "Epoch 75/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0698 - mae: 0.1635 - val_loss: 0.0199 - val_correlationLoss: 0.0199 - val_correlationMetric: 0.0193 - val_mse: 0.0723 - val_mae: 0.1648\n",
      "Epoch 76/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0185 - mse: 0.0696 - mae: 0.1625 - val_loss: 0.0237 - val_correlationLoss: 0.0237 - val_correlationMetric: 0.0231 - val_mse: 0.0785 - val_mae: 0.1681\n",
      "Epoch 77/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0697 - mae: 0.1637 - val_loss: 0.0197 - val_correlationLoss: 0.0197 - val_correlationMetric: 0.0191 - val_mse: 0.0689 - val_mae: 0.1598\n",
      "Epoch 78/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0695 - mae: 0.1628 - val_loss: 0.0178 - val_correlationLoss: 0.0178 - val_correlationMetric: 0.0173 - val_mse: 0.0717 - val_mae: 0.1721\n",
      "Epoch 79/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0697 - mae: 0.1631 - val_loss: 0.0173 - val_correlationLoss: 0.0173 - val_correlationMetric: 0.0168 - val_mse: 0.0689 - val_mae: 0.1648\n",
      "Epoch 80/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0695 - mae: 0.1619 - val_loss: 0.0191 - val_correlationLoss: 0.0191 - val_correlationMetric: 0.0186 - val_mse: 0.0610 - val_mae: 0.1578\n",
      "Epoch 81/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0184 - mse: 0.0695 - mae: 0.1631 - val_loss: 0.0185 - val_correlationLoss: 0.0185 - val_correlationMetric: 0.0180 - val_mse: 0.0669 - val_mae: 0.1564\n",
      "Epoch 82/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0698 - mae: 0.1633 - val_loss: 0.0185 - val_correlationLoss: 0.0185 - val_correlationMetric: 0.0180 - val_mse: 0.0689 - val_mae: 0.1597\n",
      "Epoch 83/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0193 - correlationLoss: 0.0193 - correlationMetric: 0.0187 - mse: 0.0699 - mae: 0.1632 - val_loss: 0.0216 - val_correlationLoss: 0.0216 - val_correlationMetric: 0.0210 - val_mse: 0.0681 - val_mae: 0.1641\n",
      "Epoch 84/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0694 - mae: 0.1621 - val_loss: 0.0208 - val_correlationLoss: 0.0208 - val_correlationMetric: 0.0203 - val_mse: 0.0711 - val_mae: 0.1600\n",
      "Epoch 85/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0696 - mae: 0.1642 - val_loss: 0.0144 - val_correlationLoss: 0.0144 - val_correlationMetric: 0.0139 - val_mse: 0.0673 - val_mae: 0.1736\n",
      "Epoch 86/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0699 - mae: 0.1632 - val_loss: 0.0200 - val_correlationLoss: 0.0200 - val_correlationMetric: 0.0195 - val_mse: 0.0733 - val_mae: 0.1623\n",
      "Epoch 87/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0192 - correlationLoss: 0.0192 - correlationMetric: 0.0187 - mse: 0.0697 - mae: 0.1629 - val_loss: 0.0172 - val_correlationLoss: 0.0172 - val_correlationMetric: 0.0167 - val_mse: 0.0655 - val_mae: 0.1609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0704 - mae: 0.1656 - val_loss: 0.0202 - val_correlationLoss: 0.0202 - val_correlationMetric: 0.0196 - val_mse: 0.0703 - val_mae: 0.1712\n",
      "Epoch 89/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0193 - correlationLoss: 0.0193 - correlationMetric: 0.0187 - mse: 0.0696 - mae: 0.1623 - val_loss: 0.0170 - val_correlationLoss: 0.0170 - val_correlationMetric: 0.0165 - val_mse: 0.0701 - val_mae: 0.1637\n",
      "Epoch 90/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0697 - mae: 0.1625 - val_loss: 0.0205 - val_correlationLoss: 0.0205 - val_correlationMetric: 0.0199 - val_mse: 0.0794 - val_mae: 0.1783\n",
      "Epoch 91/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0699 - mae: 0.1629 - val_loss: 0.0151 - val_correlationLoss: 0.0151 - val_correlationMetric: 0.0147 - val_mse: 0.0619 - val_mae: 0.1522\n",
      "Epoch 92/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0697 - mae: 0.1625 - val_loss: 0.0177 - val_correlationLoss: 0.0177 - val_correlationMetric: 0.0171 - val_mse: 0.0769 - val_mae: 0.1804\n",
      "Epoch 93/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0695 - mae: 0.1627 - val_loss: 0.0146 - val_correlationLoss: 0.0146 - val_correlationMetric: 0.0141 - val_mse: 0.0646 - val_mae: 0.1597\n",
      "Epoch 94/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0695 - mae: 0.1619 - val_loss: 0.0157 - val_correlationLoss: 0.0157 - val_correlationMetric: 0.0153 - val_mse: 0.0640 - val_mae: 0.1583\n",
      "Epoch 95/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0696 - mae: 0.1621 - val_loss: 0.0183 - val_correlationLoss: 0.0183 - val_correlationMetric: 0.0178 - val_mse: 0.0716 - val_mae: 0.1712\n",
      "Epoch 96/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0695 - mae: 0.1629 - val_loss: 0.0200 - val_correlationLoss: 0.0200 - val_correlationMetric: 0.0195 - val_mse: 0.0706 - val_mae: 0.1607\n",
      "Epoch 97/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0694 - mae: 0.1619 - val_loss: 0.0219 - val_correlationLoss: 0.0219 - val_correlationMetric: 0.0214 - val_mse: 0.0657 - val_mae: 0.1549\n",
      "Epoch 98/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0190 - correlationLoss: 0.0190 - correlationMetric: 0.0185 - mse: 0.0696 - mae: 0.1631 - val_loss: 0.0171 - val_correlationLoss: 0.0171 - val_correlationMetric: 0.0167 - val_mse: 0.0675 - val_mae: 0.1656\n",
      "Epoch 99/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0696 - mae: 0.1626 - val_loss: 0.0235 - val_correlationLoss: 0.0235 - val_correlationMetric: 0.0229 - val_mse: 0.0722 - val_mae: 0.1625\n",
      "Epoch 100/100\n",
      "1024/1024 [==============================] - 1s 1ms/step - loss: 0.0191 - correlationLoss: 0.0191 - correlationMetric: 0.0186 - mse: 0.0694 - mae: 0.1622 - val_loss: 0.0205 - val_correlationLoss: 0.0205 - val_correlationMetric: 0.0199 - val_mse: 0.0765 - val_mae: 0.1662\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "#%time history = model.fit(traindataset, epochs=epochs, steps_per_epoch=steps, validation_data=validationdataset, validation_steps=validationsamples // batchsize, callbacks=[terminate_nan,early_stop])\n",
    "%time history = model.fit(traindataset, epochs=epochs, steps_per_epoch=steps, validation_data=validationdataset, validation_steps=validationsamples // batchsize)\n",
    "#%time history = model.fit(tdataset, epochs=epochs, steps_per_epoch=steps, validation_split=0.1, callbacks=[terminate_nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01912948489189148 0.1383093810697289\n",
      "0.0204642154276371 0.14305319090337376\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (128, 64)                 192       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (128, 32)                 2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (128, 2)                  66        \n",
      "=================================================================\n",
      "Total params: 2,338\n",
      "Trainable params: 2,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 100, 'steps': 1024}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.history['loss'][-1], np.sqrt(history.history['loss'][-1]))\n",
    "print(history.history['val_loss'][-1], np.sqrt(history.history['val_loss'][-1]))\n",
    "#plot_history(history)\n",
    "#print(datetime.datetime.now())\n",
    "pd.DataFrame(history.history).plot(logy=True, figsize=(12.5,12.5))\n",
    "model.summary()\n",
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame(model.predict(data.filter(regex='_d').to_numpy()))\n",
    "p.columns = data.filter(regex='_g').columns.str.replace('_g','_p')\n",
    "p.index = data.index\n",
    "data = data.join(p)\n",
    "data['y_o'] = data.y_p - data.y_g  # \"offset\"\n",
    "data['z_o'] = data.z_p - data.z_g \n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how we are doing on the correlation\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(data.sample(1000).reset_index()).mark_point(size=0.1).encode(\n",
    "  x='x_d',\n",
    "  y='y_p'\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(data.sample(1000).reset_index()).mark_point(size=0.1).encode(\n",
    "  x='x_d',\n",
    "  y='y_g'\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(data.sample(1000).reset_index()).mark_point(size=0.1).encode(\n",
    "  x='x_d',\n",
    "  y='y_o'\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting is also how the difference depends on p - which is what we correlate\n",
    "\n",
    "alt.Chart(data.sample(1000).reset_index()).mark_point(size=0.1).encode(\n",
    "  x='y_p',\n",
    "  y='y_o'\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's the actual data on which we maximize the correlation\n",
    "\n",
    "alt.Chart(data.sample(1000).reset_index()).mark_point(size=0.1).encode(\n",
    "  x='y_p',\n",
    "  y='y_g'\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
