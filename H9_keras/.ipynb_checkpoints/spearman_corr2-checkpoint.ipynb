{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "import keras.backend as K\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy spearman: -0.39999999999999997\n",
      "tf spearman -0.4\n",
      "SpearmanrResult(correlation=-0.39999999999999997, pvalue=0.5046315754686911)\n"
     ]
    }
   ],
   "source": [
    "def spearman_correlation(predictions, targets):\n",
    "#From:https: //github.com/numerai/example-scripts/blob/master/example_model.py#L21\n",
    "\n",
    "    if not isinstance(predictions, pd.Series):\n",
    "        predictions = pd.Series(predictions)\n",
    "        \n",
    "    ranked_preds = predictions.rank(pct = True, method = \"first\")\n",
    "    return np.corrcoef(ranked_preds, targets)[0, 1]\n",
    "\n",
    "def corrcoef(x, y):\n",
    "#np.corrcoef() implemented with tf primitives\n",
    "\n",
    "    mx = tf.math.reduce_mean(x)\n",
    "    my = tf.math.reduce_mean(y)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = tf.math.reduce_sum(xm * ym)\n",
    "    r_den = tf.norm(xm) * tf.norm(ym)\n",
    "    return r_num / (r_den + tf.keras.backend.epsilon())\n",
    "\n",
    "def tf_spearman_correlation(predictions, targets):\n",
    "    ranked_preds = tf.cast(tf.argsort(tf.argsort(predictions, stable = True)), targets.dtype)\n",
    "    return corrcoef(ranked_preds, targets)\n",
    "\n",
    "targets = np.array([0.0, 0.25, 0.5, 0.75, 1.0], dtype = np.float32)\n",
    "predictions = np.random.rand(targets.shape[0])\n",
    "\n",
    "print(\"numpy spearman:\", spearman_correlation(predictions, targets))\n",
    "result = tf_spearman_correlation(tf.convert_to_tensor(predictions, dtype=tf.float32), tf.convert_to_tensor(targets, dtype=tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    scalar = result.eval()\n",
    "\n",
    "print(\"tf spearman\", scalar)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "print (spearmanr(targets,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_loss(y_true: tf.Tensor,\n",
    "                                 y_pred: tf.Tensor) -> float:\n",
    "    \"\"\"Spearman correlation coefficient\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    y = tf.cast(tf.argsort(tf.argsort(y, stable = True)), targets.dtype) #argsort is not a differentiable operation\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "\n",
    "    return 1 - K.square(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_metric(y_true: tf.Tensor,\n",
    "                                 y_pred: tf.Tensor) -> float:\n",
    "    \"\"\"Spearman correlation coefficient\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    y = tf.cast(tf.argsort(tf.argsort(y, stable = True)), targets.dtype) #argsort is not a differentiable operation\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "\n",
    "    return 1 - K.square(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=num_features, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainX)\n",
    "# transform training dataset\n",
    "trainX = scaler.transform(trainX)\n",
    "# transform test dataset\n",
    "testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 298us/step - loss: 1.3150 - spearman_metric: 1.0000 - val_loss: 0.4676 - val_spearman_metric: 1.0000\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.3490 - spearman_metric: 1.0000 - val_loss: 0.2595 - val_spearman_metric: 1.0000\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.2083 - spearman_metric: 1.0000 - val_loss: 0.1947 - val_spearman_metric: 1.0000\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.1408 - spearman_metric: 1.0000 - val_loss: 0.1555 - val_spearman_metric: 1.0000\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.1061 - spearman_metric: 1.0000 - val_loss: 0.1293 - val_spearman_metric: 1.0000\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0878 - spearman_metric: 1.0000 - val_loss: 0.1091 - val_spearman_metric: 1.0000\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0787 - spearman_metric: 1.0000 - val_loss: 0.0952 - val_spearman_metric: 1.0000\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0653 - spearman_metric: 1.0000 - val_loss: 0.0901 - val_spearman_metric: 1.0000\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0567 - spearman_metric: 1.0000 - val_loss: 0.0776 - val_spearman_metric: 1.0000\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0499 - spearman_metric: 1.0000 - val_loss: 0.0690 - val_spearman_metric: 1.0000\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0443 - spearman_metric: 1.0000 - val_loss: 0.0635 - val_spearman_metric: 1.0000\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0411 - spearman_metric: 1.0000 - val_loss: 0.0547 - val_spearman_metric: 1.0000\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0366 - spearman_metric: 1.0000 - val_loss: 0.0579 - val_spearman_metric: 1.0000\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0324 - spearman_metric: 1.0000 - val_loss: 0.0512 - val_spearman_metric: 1.0000\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0284 - spearman_metric: 1.0000 - val_loss: 0.0444 - val_spearman_metric: 1.0000\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0248 - spearman_metric: 1.0000 - val_loss: 0.0413 - val_spearman_metric: 1.0000\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0228 - spearman_metric: 1.0000 - val_loss: 0.0393 - val_spearman_metric: 1.0000\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0216 - spearman_metric: 1.0000 - val_loss: 0.0348 - val_spearman_metric: 1.0000\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0192 - spearman_metric: 1.0000 - val_loss: 0.0337 - val_spearman_metric: 1.0000\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0185 - spearman_metric: 1.0000 - val_loss: 0.0322 - val_spearman_metric: 1.0000\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0167 - spearman_metric: 1.0000 - val_loss: 0.0307 - val_spearman_metric: 1.0000\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0152 - spearman_metric: 1.0000 - val_loss: 0.0289 - val_spearman_metric: 1.0000\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0150 - spearman_metric: 1.0000 - val_loss: 0.0274 - val_spearman_metric: 1.0000\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0146 - spearman_metric: 1.0000 - val_loss: 0.0259 - val_spearman_metric: 1.0000\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0131 - spearman_metric: 1.0000 - val_loss: 0.0256 - val_spearman_metric: 1.0000\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0131 - spearman_metric: 1.0000 - val_loss: 0.0250 - val_spearman_metric: 1.0000\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0120 - spearman_metric: 1.0000 - val_loss: 0.0228 - val_spearman_metric: 1.0000\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0114 - spearman_metric: 1.0000 - val_loss: 0.0236 - val_spearman_metric: 1.0000\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0107 - spearman_metric: 1.0000 - val_loss: 0.0222 - val_spearman_metric: 1.0000\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0105 - spearman_metric: 1.0000 - val_loss: 0.0222 - val_spearman_metric: 1.0000\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0099 - spearman_metric: 1.0000 - val_loss: 0.0209 - val_spearman_metric: 1.0000\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0097 - spearman_metric: 1.0000 - val_loss: 0.0199 - val_spearman_metric: 1.0000\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0096 - spearman_metric: 1.0000 - val_loss: 0.0195 - val_spearman_metric: 1.0000\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0092 - spearman_metric: 1.0000 - val_loss: 0.0202 - val_spearman_metric: 1.0000\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0093 - spearman_metric: 1.0000 - val_loss: 0.0185 - val_spearman_metric: 1.0000\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0094 - spearman_metric: 1.0000 - val_loss: 0.0223 - val_spearman_metric: 1.0000\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0086 - spearman_metric: 1.0000 - val_loss: 0.0185 - val_spearman_metric: 1.0000\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0081 - spearman_metric: 1.0000 - val_loss: 0.0180 - val_spearman_metric: 1.0000\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0079 - spearman_metric: 1.0000 - val_loss: 0.0190 - val_spearman_metric: 1.0000\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0083 - spearman_metric: 1.0000 - val_loss: 0.0190 - val_spearman_metric: 1.0000\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0082 - spearman_metric: 1.0000 - val_loss: 0.0164 - val_spearman_metric: 1.0000\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0076 - spearman_metric: 1.0000 - val_loss: 0.0168 - val_spearman_metric: 1.0000\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0070 - spearman_metric: 1.0000 - val_loss: 0.0158 - val_spearman_metric: 1.0000\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0070 - spearman_metric: 1.0000 - val_loss: 0.0154 - val_spearman_metric: 1.0000\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0070 - spearman_metric: 1.0000 - val_loss: 0.0165 - val_spearman_metric: 1.0000\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0065 - spearman_metric: 1.0000 - val_loss: 0.0151 - val_spearman_metric: 1.0000\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0062 - spearman_metric: 1.0000 - val_loss: 0.0150 - val_spearman_metric: 1.0000\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0061 - spearman_metric: 1.0000 - val_loss: 0.0143 - val_spearman_metric: 1.0000\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0059 - spearman_metric: 1.0000 - val_loss: 0.0146 - val_spearman_metric: 1.0000\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0059 - spearman_metric: 1.0000 - val_loss: 0.0143 - val_spearman_metric: 1.0000\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0058 - spearman_metric: 1.0000 - val_loss: 0.0140 - val_spearman_metric: 1.0000\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 38us/step - loss: 0.0057 - spearman_metric: 1.0000 - val_loss: 0.0135 - val_spearman_metric: 1.0000\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0056 - spearman_metric: 1.0000 - val_loss: 0.0133 - val_spearman_metric: 1.0000\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0055 - spearman_metric: 1.0000 - val_loss: 0.0130 - val_spearman_metric: 1.0000\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0054 - spearman_metric: 1.0000 - val_loss: 0.0134 - val_spearman_metric: 1.0000\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0052 - spearman_metric: 1.0000 - val_loss: 0.0127 - val_spearman_metric: 1.0000\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0051 - spearman_metric: 1.0000 - val_loss: 0.0127 - val_spearman_metric: 1.0000\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0050 - spearman_metric: 1.0000 - val_loss: 0.0131 - val_spearman_metric: 1.0000\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0051 - spearman_metric: 1.0000 - val_loss: 0.0125 - val_spearman_metric: 1.0000\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0049 - spearman_metric: 1.0000 - val_loss: 0.0121 - val_spearman_metric: 1.0000\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0048 - spearman_metric: 1.0000 - val_loss: 0.0121 - val_spearman_metric: 1.0000\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0047 - spearman_metric: 1.0000 - val_loss: 0.0119 - val_spearman_metric: 1.0000\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0046 - spearman_metric: 1.0000 - val_loss: 0.0118 - val_spearman_metric: 1.0000\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0045 - spearman_metric: 1.0000 - val_loss: 0.0118 - val_spearman_metric: 1.0000\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0046 - spearman_metric: 1.0000 - val_loss: 0.0124 - val_spearman_metric: 1.0000\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0044 - spearman_metric: 1.0000 - val_loss: 0.0111 - val_spearman_metric: 1.0000\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0044 - spearman_metric: 1.0000 - val_loss: 0.0113 - val_spearman_metric: 1.0000\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0046 - spearman_metric: 1.0000 - val_loss: 0.0110 - val_spearman_metric: 1.0000\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0042 - spearman_metric: 1.0000 - val_loss: 0.0110 - val_spearman_metric: 1.0000\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0041 - spearman_metric: 1.0000 - val_loss: 0.0107 - val_spearman_metric: 1.0000\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0041 - spearman_metric: 1.0000 - val_loss: 0.0107 - val_spearman_metric: 1.0000\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0040 - spearman_metric: 1.0000 - val_loss: 0.0108 - val_spearman_metric: 1.0000\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0040 - spearman_metric: 1.0000 - val_loss: 0.0105 - val_spearman_metric: 1.0000\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0041 - spearman_metric: 1.0000 - val_loss: 0.0106 - val_spearman_metric: 1.0000\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0041 - spearman_metric: 1.0000 - val_loss: 0.0110 - val_spearman_metric: 1.0000\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0041 - spearman_metric: 1.0000 - val_loss: 0.0108 - val_spearman_metric: 1.0000\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 54us/step - loss: 0.0040 - spearman_metric: 1.0000 - val_loss: 0.0101 - val_spearman_metric: 1.0000\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0038 - spearman_metric: 1.0000 - val_loss: 0.0103 - val_spearman_metric: 1.0000\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0038 - spearman_metric: 1.0000 - val_loss: 0.0098 - val_spearman_metric: 1.0000\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0037 - spearman_metric: 1.0000 - val_loss: 0.0101 - val_spearman_metric: 1.0000\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0037 - spearman_metric: 1.0000 - val_loss: 0.0097 - val_spearman_metric: 1.0000\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0035 - spearman_metric: 1.0000 - val_loss: 0.0095 - val_spearman_metric: 1.0000\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0036 - spearman_metric: 1.0000 - val_loss: 0.0094 - val_spearman_metric: 1.0000\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0035 - spearman_metric: 1.0000 - val_loss: 0.0093 - val_spearman_metric: 1.0000\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0035 - spearman_metric: 1.0000 - val_loss: 0.0093 - val_spearman_metric: 1.0000\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0034 - spearman_metric: 1.0000 - val_loss: 0.0095 - val_spearman_metric: 1.0000\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0033 - spearman_metric: 1.0000 - val_loss: 0.0103 - val_spearman_metric: 1.0000\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0034 - spearman_metric: 1.0000 - val_loss: 0.0092 - val_spearman_metric: 1.0000\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0032 - spearman_metric: 1.0000 - val_loss: 0.0093 - val_spearman_metric: 1.0000\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0032 - spearman_metric: 1.0000 - val_loss: 0.0091 - val_spearman_metric: 1.0000\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0032 - spearman_metric: 1.0000 - val_loss: 0.0089 - val_spearman_metric: 1.0000\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0031 - spearman_metric: 1.0000 - val_loss: 0.0089 - val_spearman_metric: 1.0000\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0032 - spearman_metric: 1.0000 - val_loss: 0.0098 - val_spearman_metric: 1.0000\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0033 - spearman_metric: 1.0000 - val_loss: 0.0090 - val_spearman_metric: 1.0000\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0030 - spearman_metric: 1.0000 - val_loss: 0.0085 - val_spearman_metric: 1.0000\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0029 - spearman_metric: 1.0000 - val_loss: 0.0087 - val_spearman_metric: 1.0000\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0029 - spearman_metric: 1.0000 - val_loss: 0.0085 - val_spearman_metric: 1.0000\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0029 - spearman_metric: 1.0000 - val_loss: 0.0085 - val_spearman_metric: 1.0000\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0028 - spearman_metric: 1.0000 - val_loss: 0.0085 - val_spearman_metric: 1.0000\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0029 - spearman_metric: 1.0000 - val_loss: 0.0082 - val_spearman_metric: 1.0000\n",
      "500/500 [==============================] - 0s 14us/step\n",
      "500/500 [==============================] - 0s 14us/step\n",
      "Spearman Train: 1.000, Spearman Test: 1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAoDUlEQVR4nO3de5zcdX3v8dfnNzN7y242yWZzJyRyD3eMCJVTrkICavB4jgWKt6opVlt7qpZg64XaCz2eetAWpIgULQL1KCpqKIhC0XINmGKAQAIJZBOSbBJy2SS7O5fP+eP7m83sZi+TMJvxN/t+Ph7z2Jnf9fOd3X3/vvOd3/zG3B0REUm+qNoFiIhIZSjQRURqhAJdRKRGKNBFRGqEAl1EpEYo0EVEaoQCXSThzOyLZnZ7teuQ6lOg1zgzW2tmF1Rx/y+a2dGDTH/IzNzMTh4w/Yfx9HMOVY0l+/6wma00s11mtsnMfmpmLYe6jkoys3PMrGBmXQNuZ1a7Nqk8BbqMGjM7Aojc/cUhFnkReH/J8m3AGUDnISivHzM7G/hb4HJ3bwGOA75bhTrSo7DZDe7ePOD26CD7NjOLBkw7oHpGqX4pkwJ9jDKzejO73sw2xLfrzaw+njfZzH5iZtvNbJuZ/bL4j25mV5vZ+rgX+4KZnT/Mbi4Blg4z/zvA75lZKn58OfADoLekzsjMlpjZS2a21cy+a2aTSub/PzPbaGY7zOxhMzu+ZN5tZnZD3NPeZWaPxweZwbwFeNTdfw3g7tvc/VvuviveVpuZ3WNmO83sCTP7kpn9Kp43J35V0Rdm8SuQj8T3jzCzX8T1bzGz75jZhJJl18bP6zPAbjNLm9kZZvZI/Dv4r9JXLGY218z+I27Tz4DJwzzHw4rr/Bsz+09gD/CmuC0fN7NVwKp4uY+a2er47+EeM5tRso39lpfqUKCPXX9B6A2fApwMnA78ZTzvU0AH0A5MBT4LuJkdA3wCeEvci70IWDvMPi4GfjrM/A3Ac8CF8eP3A98esMyfAJcCZwMzgNeBG0rm3wscBUwBniYcJEpdDlwLTARWA38zRC2PAxeZ2bVm9rbiwa3EDUA3MB34g/hWLgP+Lq7/OOAw4IuD1HkJMIHwnP8U+GtgEvBp4Ptm1h4vewfwFCHIvwR84ABqGcz7gMVAC/BKPO1S4K3APDM7L67/vYT2vwLcNWAbfcu/wVrkjXB33Wr4RgjcCwaZ/hJwccnji4C18f2/An4EHDlgnSOBzcAFQGaE/TYBW4GGIeY/BHwEuBK4EzgGeDGe1wGcE99/Hji/ZL3pQBZID7LNCYADrfHj24BbSuZfDKwcpuaFwI+B7UAX8BUgFd+ywLEly/4t8Kv4/px4v+mB7RtiP5cCvx7wO/qDksdXA/86YJ37CME9G8gB40rm3QHcPsS+zgEKcZtKb+NK6vyrAes4cF7J428C/7vkcXP8fMwZbHndqndTD33smsG+3hjx/eLL6C8TerP3m9nLZrYEwN1XA39K6F1uNrO7Sl96D3A+8Ii7d49Qx93AecAfA/86yPzDgR/EQw/bCQGfB6aaWcrMrouHY3ay79VC6RDExpL7ewhhNCh3v9fd30noFS8CPkg46LQDaWBdyeKv7LeBIZjZlPi5Wh/XeTv7D5OUbvtw4H8W2xy3+yzCwWwG8Lq77z6AWja4+4QBt9L11w2yTum0fn8r7t5FOFjPHGEbcogp0MeuDYTgKJodT8Pdd7n7p9z9TcA7gT8rjpW7+x3ufla8rgN/P8T2RxpuId7eHsKwyccYPNDXAQsHhFGDu68HriAE7wVAK6GnDGGI46C5e8Hdfw78AjiB8CZtjjBUUjS75H4xHJtKpk0ruf93hOfqJHcfT3hVMrDG0sueriP00EvbPM7drwNeAyaa2bghajkYg11ytXRav7+VeN9twPoRtiGHmAJ9bMiYWUPJLU0Y5vhLM2s3s8nA5wk9R8zsHWZ2pJkZsJPQI86b2TFmdl48vtwN7I3nDWYhw78hWuqzwNnuvnaQeTcBf2Nmh8e1tZvZonheC9BD6C02EYZBDoqZLTKzy8xsogWnE8btH3P3POGVxBfNrMnM5lEybu3unYRwuzJ+1fAHQOmbry2EIZztZjYT+MwI5dwOvNPMLoq312Dh9MNZ7v4KsAy41szqzOwswkF3NN0BfMjMTol/938LPD7E70uqSIE+NiwlhG/x9kXCG27LgGeA3xDeUPzrePmjgAcIIfQocKO7PwTUA9cBWwhDGVMIYdyPmZ0AdLn7q+UU5+4b3P1XQ8z+KnAPYfhnF/AY4c03CG+gvkII0+fieQfrdeCjhLM0isMiX3b34pusnyAM12wkjM3/y4D1P0oI6q3A8cAjJfOuBU4DdhBetdw9XCHuvo7wyuOzhFcH6+JtF/9fryA8B9uAL7D/G8kDzbD9z0N/zwjrlNbzc+BzwPcJrxCOAC4rd305dMxdr5Sksszsz4HJ7v7n1a5ltJjZBwlvep5V7VpEivQhABkNawlni4jIIaRAl4pz90P+CUsR0ZCLiEjN0JuiIiI1ompDLpMnT/Y5c+ZUa/ciIon01FNPbXH39sHmVS3Q58yZw7Jly6q1exGRRDKzIT8ZrCEXEZEaoUAXEakRCnQRkRqh89BFJFGy2SwdHR10d490Ic9ka2hoYNasWWQymbLXUaCLSKJ0dHTQ0tLCnDlzCNePqz3uztatW+no6GDu3Lllr6chFxFJlO7ubtra2mo2zAHMjLa2tgN+FaJAF5HEqeUwLzqYNiYu0F/YuIt/uP8Ftnb1VLsUEZHfKokL9Jc6u/jHX6xmS1fvyAuLiFTY9u3bufHGGw94vYsvvpjt27dXvqASiQv0dBRehmTzhSpXIiJj0VCBns8P9eVdwdKlS5kwYcIoVRUk7iyXTCocgxToIlINS5Ys4aWXXuKUU04hk8nQ3NzM9OnTWb58Oc899xyXXnop69ato7u7m09+8pMsXrwY2He5k66uLhYuXMhZZ53FI488wsyZM/nRj35EY2PjG64twYGuy/6KjHXX/vhZntuws6LbnDdjPF945/FDzr/uuutYsWIFy5cv56GHHuKSSy5hxYoVfacX3nrrrUyaNIm9e/fylre8hfe85z20tbX128aqVau48847+cY3vsF73/tevv/973PllVe+4doTF+jpVBhyyamHLiK/BU4//fR+54p/7Wtf4wc/+AEA69atY9WqVfsF+ty5cznllFMAePOb38zatWsrUkviAr2vh15QD11krBuuJ32ojBs3ru/+Qw89xAMPPMCjjz5KU1MT55xzzqDnktfX1/fdT6VS7N27tyK1JO5N0UzcQ8/m1EMXkUOvpaWFXbt2DTpvx44dTJw4kaamJlauXMljjz12SGtLXA89HYVjUK6gQBeRQ6+trY23ve1tnHDCCTQ2NjJ16tS+eQsWLOCmm27ipJNO4phjjuGMM844pLUlLtDr0qGH3qs3RUWkSu64445Bp9fX13PvvfcOOq84Tj558mRWrFjRN/3Tn/50xepK3JBLXw9db4qKiPSTuEDPpIuBrh66iEip5AV6VBxyUQ9dRKRU4gI9ndKQi4jIYBIX6H2nLWrIRUSknxED3cxuNbPNZrZiiPm/b2bPxLdHzOzkype5z74PFqmHLiJSqpwe+m3AgmHmrwHOdveTgC8BN1egriFlUnpTVESq52Avnwtw/fXXs2fPngpXtM+Ige7uDwPbhpn/iLu/Hj98DJhVodoGlYoMM11tUUSq47c50Cv9waIPA4OfVV9BmSjSGLqIVEXp5XPf/va3M2XKFL773e/S09PDu9/9bq699lp2797Ne9/7Xjo6Osjn83zuc59j06ZNbNiwgXPPPZfJkyfz4IMPVry2igW6mZ1LCPSzhllmMbAYYPbs2Qe9r0zK1EMXEbh3CWz8TWW3Oe1EWHjdkLNLL597//33873vfY8nnngCd+dd73oXDz/8MJ2dncyYMYOf/vSnQLjGS2trK1/5yld48MEHmTx5cmVrjlXkLBczOwm4BVjk7luHWs7db3b3+e4+v729/aD3l05FOm1RRKru/vvv5/777+fUU0/ltNNOY+XKlaxatYoTTzyRBx54gKuvvppf/vKXtLa2HpJ63nAP3cxmA3cD73P3F994SSPLpCJdy0VEhu1JHwruzjXXXMMf/uEf7jfvqaeeYunSpVxzzTVceOGFfP7znx/1eso5bfFO4FHgGDPrMLMPm9lVZnZVvMjngTbgRjNbbmbLRrFeIAy5qIcuItVQevnciy66iFtvvZWuri4A1q9fz+bNm9mwYQNNTU1ceeWVfPrTn+bpp5/eb93RMGIP3d0vH2H+R4CPVKyiMmRSETl9wYWIVEHp5XMXLlzIFVdcwZlnnglAc3Mzt99+O6tXr+Yzn/kMURSRyWT4+te/DsDixYtZuHAh06dPH5U3Rc29OsE4f/58X7bs4Drz5/3DQxw3fTw3XHFahasSkd92zz//PMcdd1y1yzgkBmurmT3l7vMHWz5xH/2HcNqihlxERPpLZqCnTeehi4gMkMhAT0eRzkMXGcOqNVR8KB1MGxMZ6HWpSNdyERmjGhoa2Lp1a02HuruzdetWGhoaDmi9xH2nKEA6ZfTm1EMXGYtmzZpFR0cHnZ2d1S5lVDU0NDBr1oFdGiuhgR6xuzdf7TJEpAoymQxz586tdhm/lRI65GJk1UMXEeknkYGejiJy+oILEZF+EhnombTeFBURGSiZgR4ZvTptUUSkn0QGejpl6qGLiAyQyEDPpPTBIhGRgRToIiI1IqGBbrp8rojIAIkM9LR66CIi+0lkoGeicLXFWr6Wg4jIgUpmoKdC2Rp2ERHZJ5GBni4Guk5dFBHpk8hAz6QMQB8uEhEpkdBAL/bQFegiIkWJDPR03EPXGLqIyD4jBrqZ3Wpmm81sxRDzzcy+ZmarzewZMzut8mX2V+yh60suRET2KaeHfhuwYJj5C4Gj4tti4OtvvKzhZdRDFxHZz4iB7u4PA9uGWWQR8G0PHgMmmNn0ShU4mGIPXR8uEhHZpxJj6DOBdSWPO+Jp+zGzxWa2zMyWvZHvA0xHCnQRkYEqEeg2yLRBx0Lc/WZ3n+/u89vb2w96h3XpeMhF56GLiPSpRKB3AIeVPJ4FbKjAdoekHrqIyP4qEej3AO+Pz3Y5A9jh7q9VYLtDKp62mFUPXUSkT3qkBczsTuAcYLKZdQBfADIA7n4TsBS4GFgN7AE+NFrFFtXpTVERkf2MGOjufvkI8x34eMUqKkPftVwKCnQRkaJEflI0oyEXEZH9JDTQNeQiIjJQIgM9Hem0RRGRgRIZ6H3XclEPXUSkT6IDXT10EZF9EhroxYtzqYcuIlKUyEBP6/K5IiL7SWSg6/K5IiL7S2igx6ctqocuItInkYFePG0xqx66iEifRAa6mZFJmT5YJCJSIpGBDuESujkFuohIn+QGesp0LRcRkRKJDfS6VKQhFxGREokN9HTK9ElREZESiQ30jHroIiL9JDvQddqiiEifxAZ6OjKd5SIiUiKxga4hFxGR/hIc6DptUUSkVIIDXT10EZFSZQW6mS0wsxfMbLWZLRlkfquZ/djM/svMnjWzD1W+1P502qKISH8jBrqZpYAbgIXAPOByM5s3YLGPA8+5+8nAOcA/mFldhWvtJ5zloh66iEhROT3004HV7v6yu/cCdwGLBizjQIuZGdAMbANyFa10AA25iIj0V06gzwTWlTzuiKeV+ifgOGAD8Bvgk+6+X9qa2WIzW2Zmyzo7Ow+y5CCctqghFxGRonIC3QaZNjBJLwKWAzOAU4B/MrPx+63kfrO7z3f3+e3t7QdYan+ZdESveugiIn3KCfQO4LCSx7MIPfFSHwLu9mA1sAY4tjIlDi6jHrqISD/lBPqTwFFmNjd+o/My4J4By7wKnA9gZlOBY4CXK1noQJmUrocuIlIqPdIC7p4zs08A9wEp4FZ3f9bMrorn3wR8CbjNzH5DGKK52t23jGLdpFMRveqhi4j0GTHQAdx9KbB0wLSbSu5vAC6sbGnDy6SMnE5bFBHpk+xPiuYU6CIiRYkN9HTKdPlcEZESiQ10fQWdiEh/iQ30dBThDnn10kVEgCQHeip83km9dBGRILGBXpcKpSvQRUSCxAZ6sYeuT4uKiASJDfSMeugiIv0kONDjMXS9KSoiAiQ40NNRKF3XcxERCRIb6Jm0hlxEREolN9Cj4mmLGnIREYEkB7reFBUR6Sexgb7vg0XqoYuIQIIDvdhD15uiIiJB4gNdPXQRkSCxgd435KIvuRARARIc6H3XctGXXIiIAAkO9L5rueiToiIiQIIDXactioj0l9xAj/SmqIhIqbIC3cwWmNkLZrbazJYMscw5ZrbczJ41s/+obJn723f5XPXQRUQA0iMtYGYp4Abg7UAH8KSZ3ePuz5UsMwG4EVjg7q+a2ZRRqrePhlxERPorp4d+OrDa3V92917gLmDRgGWuAO5291cB3H1zZcvcX0afFBUR6aecQJ8JrCt53BFPK3U0MNHMHjKzp8zs/YNtyMwWm9kyM1vW2dl5cBXH1EMXEemvnEC3QaYN7BangTcDlwAXAZ8zs6P3W8n9Znef7+7z29vbD7jYfjvUaYsiIv2MOIZO6JEfVvJ4FrBhkGW2uPtuYLeZPQycDLxYkSoHse8sF/XQRUSgvB76k8BRZjbXzOqAy4B7BizzI+C/mVnazJqAtwLPV7bU/qLISEWmQBcRiY3YQ3f3nJl9ArgPSAG3uvuzZnZVPP8md3/ezP4deAYoALe4+4rRLBwgHRk5vSkqIgKUN+SCuy8Flg6YdtOAx18Gvly50kZWl4roVQ9dRARI8CdFIbwxqh66iEiQ8ECPyOnyuSIiQMIDvS4V0ZtTD11EBBIe6OmUqYcuIhJLdKBnUpFOWxQRiSU60NOR6VouIiKxRAd6JhXp8rkiIrGEB7p66CIiRYkO9LTG0EVE+iQ60OsU6CIifRId6OG0RQ25iIhA0gM9ijSGLiISS3Sg16V1+VwRkaLkBfqL98FXT4bXXyEd6bRFEZGi5AW6peD1tbDrtfiTohpyERGBJAZ6y9Twc9fG+Dx09dBFRCCJgd48Lfzs2hQ+KaqzXEREgCQGelMbRGnYtZF0ysjm1EMXEYEkBnoUwbgpfT30rC6fKyICJDHQAVqmlYyha8hFRASSHOhdm0hHEfmCU9A4uohIeYFuZgvM7AUzW21mS4ZZ7i1mljez/1G5EgfRPBV2baQuHcrXsIuISBmBbmYp4AZgITAPuNzM5g2x3N8D91W6yP20TIM9W6gjB0BOwy4iImX10E8HVrv7y+7eC9wFLBpkuT8Gvg9srmB9g2sO56K35F8HFOgiIlBeoM8E1pU87oin9TGzmcC7gZuG25CZLTazZWa2rLOz80Br3aclnIs+PrsFgF59uEhEpKxAt0GmDewSXw9c7e754Tbk7je7+3x3n9/e3l5miYOIe+jNua0A5DSGLiJCuoxlOoDDSh7PAjYMWGY+cJeZAUwGLjaznLv/sBJF7ifuoTf3bgXayeY05CIiUk6gPwkcZWZzgfXAZcAVpQu4+9zifTO7DfjJqIU5hA8WYTT1dgLH6iwXERHKCHR3z5nZJwhnr6SAW939WTO7Kp4/7Lj5qEilYVw7TT1hDF1vioqIlNdDx92XAksHTBs0yN39g2+8rDK0TKUxDnRdcVFEJKmfFAVonkZ9dzhTRoEuIpLkQG+Z2hfovbrioohIggO9eRp13Z1EFHhtR3e1qxERqbrkBnrLNMwLtNlO1mzZXe1qRESqLrmBHn+46PiWvazdqkAXEUluoMcfLjq+Za966CIi1ECgH9nUxZotu3HXuegiMrYlN9DjIZfZmV3s6s6xbXdvlQsSEamu5AZ6uh4aJzI1CpfQ1Ti6iIx1yQ10gOZpTCyEQF+zZU+VixERqa5kB3r88f9UZKzVG6MiMsYlO9CbpxF1bWTWxEbWaMhFRMa4ZAd6y1To2sTctib10EVkzEt2oDdPg3wvx03I69RFERnzkh3oLeHUxWPH7WZPb57OXT1VLkhEpHqSHeiT3gTA0awF0CdGRWRMS3agTzsZmqdx+OYHAZ2LLiJjW7IDPYrg2EtofPUhmlNZnYsuImNasgMd4NhLsOxuFo1/UWe6iMiYlvxAn/PfoL6VBamnNOQiImNa8gM9XQdHX8hp3Y/x6padFAo6dVFExqayAt3MFpjZC2a22syWDDL/983smfj2iJmdXPlSh3HsOxiX286J+ZVs3KmvoxORsWnEQDezFHADsBCYB1xuZvMGLLYGONvdTwK+BNxc6UKHdeQFFKI6Lkwt06mLIjJmldNDPx1Y7e4vu3svcBewqHQBd3/E3V+PHz4GzKpsmSOobyY/9xwuSj3JYy9tOaS7FhH5bVFOoM8E1pU87oinDeXDwL2DzTCzxWa2zMyWdXZ2ll9lGTLHv5NZtoU1v3mkotsVEUmKcgLdBpk26DuPZnYuIdCvHmy+u9/s7vPdfX57e3v5VZbj2HfQm2piwY5/o+N1nY8uImNPOYHeARxW8ngWsGHgQmZ2EnALsMjdt1amvAPQNImuUxfzjtRjLH/iPw757kVEqq2cQH8SOMrM5ppZHXAZcE/pAmY2G7gbeJ+7v1j5Mssz6YI/YyfNzPz1/61WCSIiVTNioLt7DvgEcB/wPPBdd3/WzK4ys6vixT4PtAE3mtlyM1s2ahUPp6GVZbPex6ndj7PnJY2li8jYYtW6hvj8+fN92bLK5/4TL6xj7h1vI5pyDG1/dD/YYG8BiIgkk5k95e7zB5uX/E+KDnDakTP5pr2Hts4n4MX7ql2OiMghU3OBnk5FdB59GauYjf/wY7D91WqXJCJySNRcoAOce8JhfLTnk+RzWfi390FWlwMQkdpXk4F+9tHtbKs/jH9s/RS8thzu/Uy1SxIRGXU1GegtDRk+deExfLXjaF469ip4+tvw2NerXZaIyKiqyUAH+P23zuaYqS18aO0F5I95B/z7EoW6iNS0mg30dCrii+86nle393Jj21/Cce8Mof7oDdUuTURkVNRsoAOceUQbl5w0nX96eC3rzrsBjnsX3PdZ+NkXINdb7fJERCqqpgMd4LMXH0cqMq687WleOfcf4bQPwH9eD984Fzb+ptrliYhUTM0H+swJjdz+kbeyc2+W//7PT/LMaX8Fl98FXZvh5nPhBx+D5XfC9nUjb0xE5LdYzQc6wGmzJ/K9j/0ODZkUl938GN/ZPo/uxY/Ayb8HL94LP7wKrj8Bbl0Am56tdrkiIgel5q7lMpzNO7u56vanePrV7bSNq+N9Zx7OB86YzcSu1fDSL8JQzN7tcOYfwdlLoL75kNYnIjKS4a7lMqYCHcDdefSlrdzyqzX8YuVm2sbVce2i47nkxOnY3tfhgS+E89YbJ8Kp74O3fBgmzjnkdYqIDEaBPoTnNuxkyd3P8EzHDi6cN5VrFx3P9NZG6FgGj3wNnv8JeAHedDYccT4ccR5MPV5XcBSRqlGgDyOXL/DNX63hKz97kXzBWXDCND74O3N48+ETsZ0b4Kl/ged/DJ0rwwqth4Ve+2kfgKZJ8UZ6ILsn9OpFREaRAr0M67bt4VuPrOW7y9axszvHUVOaueSk6bzjpOkcOaUFdqyHlx+EZ/4N1jwM6QY47PRwdsz2V0JPftbpMO9d4Xz3iYdXu0kiUoMU6AdgT2+OHy3fwA9+vZ4n127DHY5oH8fvHt3O7x7dzlvnTqLp9Rfg8X8OF/6aOBcmHw1RGlb+BDY+EzY0880w79IQ8BMO1zCNiFSEAv0gbdrZzdLfvMYvVm7miTXb6MkVgHBu+xFTmjl6SjOnzJ7AqbMnMqO1ATODbWvguR/Csz8MgQ9QPx7ajoC2I2H8DGieCi3TYNrJYbrCXkTKpECvgO5snsfXbGP5q9t5eUsXL3V2sWpTV1/IT2mp56RZEzh5VisnzmrlxJmttPWuh1UPwJYXYesq2PYy7NoI+ZLLDjROglnzoWU61LdAXTM0TgjTGyeGcfqmSeFxQ6vCX2SMU6CPkt5cgZUbd/L0K6+zfN12nunYwctbdvfNn97awPEzWjluegtHT23hmGktTB9fT7PvxnZ2wPqnoeMJWP9r2LMVenZBdvfQO4wyMG5yuDW1hZBvmtT/fn1LGP6JUuFnugFSdeFAMX461I07BM+MiIwWBfohtLM7y4r1O3h2/U5WbNjBivU7WLt1D/nCvue5qS7FlJZ6WhszjG/MML4hw5Tx9cxobWR6a4ZJUTfjCjtpyu1gvO+ilV3U92zD9m6D3Z2we0s4AOzZFn527wDK/D02tIYDQPHMnHw2DAk1TgyvDLB4WxY+WNUwIaxT3xwOCnXNkK4LB4koA4Vc2E6uOxw8xk2GpsmwdxtsXAGbVoT9Tj0Bpp0YzulP10MqE6b37oaeLsjtDW8su4dtt84Kt+JyIgJUINDNbAHwVSAF3OLu1w2Yb/H8i4E9wAfd/enhtlmrgT6Y7myelzt3s2rzLjbt7GbTzh427+ph594sO7uz7NibZdOObnb35ofcRmMmxaRxdbQ2ZpjQlKExkyKKjJQZ6ahAq3fRShfjU92Mr4sYX2+MSzupQpao0EtDYTfjs5209G6mIbsDyzRgdeOI0hnSvbtI924n1bMTw8EMg/CKoXt7OGD0dIEPXd/gLLxvALB1NWUfdPpWT8G49rBePhsCP9MUXmXUjQsHhigTXo1k94Z6e7vCgaV4gErVxduKwv1MY7hZFA5G+WwYxorS4WYpiKLwM5UJ66Tqwn1Lxa98UmF9S4V1C3koZPcdjDKN4WdxeMw97Kt4izKh9uKBrXhwtJIrcZiV1DLwCh22b7+5Hsj3hH00tIZb3bjwXBXy4bmL0vHzFIV1+zYT7Xs1VzodD9vD4xrS8brF2R62ne8N7S5uCyt5rjQ0OFqGC/R0GSungBuAtwMdwJNmdo+7P1ey2ELgqPj2VuDr8U8BGjIp5s0Yz7wZ44dcxt3Z2Z3jtR176erO0Z0t0J3Ns31vlq1dPWzp6mHb7iw79vby+p5wEMgXHHfIFgrk8pDLN7G7t56d3Vn2Hacb4p9twOyyazaDulREXTqiPh0RpaAxytFs3dRZjjry1FmOQpSmEDWQT9XTYD2Mz++gtbCDLmvildThdOfrSaeMCVOyHMmrTGUr9VGeesuTMiObaiKbbiJrdWQLRq7gRIUe2rIbactuZEJ+GxaloCFDZEY9vTT4Xup6ukl3Z4kKe4g8Ry7VSG9qOr0N46jzbhr27KJh5zoiz2GAUSAqZEnnu4nyPRiOWwqPwr+AeQ4r5DEvuRVy4QAneBz45TwfbhGkGyGVxtzDwQVC0BcPwIV86CB4fMBJxdP7DiDxQaZ4YLAoPsjFB5biAceJX9nlw0E9uyf8TGXC8GN9K6TS+5YvbtOifQflgfsq5MIrx+Ir2Exj6CQUD9TFg1axbV7ov82hFIdBowwcswBOeM+B/yJGMGKgA6cDq939ZQAzuwtYBJQG+iLg2x66+4+Z2QQzm+7ur1W84hplZrQ2ZmhtfONDDPmCs3Nvlq6eXN+0XMHZ3ZOjqyfH7p4cvbkCvfkCPdkCPbk8PblwACl4WD9fcLL5Aj3xcoV4Wt7DQcTdw7Lu5PIFcnnHgb3MpNsAjHYL/b5cwenOZviv7FF0Z48gmy+EW67Qtw0IB5BMyogiA47C41qKdfRk8/TmC2Tzhy5kU+TJkKOOHBEFUvGteN8Mch6RD4+oI0e99VJPtt92cqTIkSJPihR56snSQC/p+MCYJt8vLCN83z5KpltftEIBo4cMPV6HmdPCHsazh0brwTHyRDhGmjwp8qQpDNiOx+3Jl0yPMzK+bp9RIE2BtIW/JY8PjzmPyJImSwjD4rbS5GmwXhqyoW0FQhBHQIrQEYisQMEjCnH4pYr7IEfKCqRwUpYPB4OSvUbxPtyKdVr8LIXW9NBOtzXQTT2ZbI5x3Xto9j2kLR+3x/qeW6NAFP9Oi4+Lz6tbxF7q2cNUcqSo917q6aWeXeFvwXJkyPWt6XH7Q42Ffoe80tcp4bnOkfI8HXum89YqBfpMoPTash3s3/sebJmZQL9AN7PFwGKA2bPL7y3KgUlFxsRxdUwcV1ftUkZFoeD05gvhwEI4wJiFWIHwiiUbH4hy+XAgyhUc93DQcYeCe9+Bq/QfsHQIsrgshINXcb1C2HHf/OIWCsXt5vcd+Ijrc4rrhn/yYr0eb7tQ8L629NVU0r7i+sX7xG2x4vAY+w6yhQHDqKnIwim18XOXzRf69uGDLF+6LYrLxLFlcZjWG9T3PT/76yYcqAtxJyBf7MTS/3krXd/j9hXbEJkNu85gv6vi81l8TszYt81C/2I9blPxfvG5dYfI9v2OSkfOim3KFfrve+Bz5wNmlO4LgwvnTR38iXuDygn0wQbDBrahnGVw95uBmyGMoZexb5H9RJHREKWGnN/I0PNEalk510PvAA4reTwL2HAQy4iIyCgqJ9CfBI4ys7lmVgdcBtwzYJl7gPdbcAawQ+PnIiKH1ohDLu6eM7NPAPcRTlu81d2fNbOr4vk3AUsJpyyuJpy2+KHRK1lERAZTzhg67r6UENql024que/AxytbmoiIHIgx8Z2iIiJjgQJdRKRGKNBFRGqEAl1EpEZU7WqLZtYJvHKQq08GtlSwnKQYi+0ei22GsdnusdhmOPB2H+7u7YPNqFqgvxFmtmyoq43VsrHY7rHYZhib7R6LbYbKtltDLiIiNUKBLiJSI5Ia6DdXu4AqGYvtHotthrHZ7rHYZqhguxM5hi4iIvtLag9dREQGUKCLiNSIxAW6mS0wsxfMbLWZLal2PaPBzA4zswfN7Hkze9bMPhlPn2RmPzOzVfHPidWutdLMLGVmvzazn8SPx0KbJ5jZ98xsZfw7P3OMtPt/xX/fK8zsTjNrqLV2m9mtZrbZzFaUTBuyjWZ2TZxtL5jZRQe6v0QFeskXVi8E5gGXm9m86lY1KnLAp9z9OOAM4ONxO5cAP3f3o4Cfx49rzSeB50sej4U2fxX4d3c/FjiZ0P6abreZzQT+BJjv7icQLs19GbXX7tuABQOmDdrG+H/8MuD4eJ0b48wrW6ICnZIvrHb3XqD4hdU1xd1fc/en4/u7CP/gMwlt/Va82LeAS6tS4Cgxs1nAJcAtJZNrvc3jgd8Fvgng7r3uvp0ab3csDTSaWRpoInzLWU21290fBrYNmDxUGxcBd7l7j7uvIXy/xOkHsr+kBfpQX0Zds8xsDnAq8DgwtfhNUPHPKVUsbTRcD/w5lHw9fe23+U1AJ/Av8VDTLWY2jhpvt7uvB/4P8Crhy+R3uPv91Hi7Y0O18Q3nW9ICvawvo64VZtYMfB/4U3ffWe16RpOZvQPY7O5PVbuWQywNnAZ83d1PBXaT/GGGEcXjxouAucAMYJyZXVndqqruDedb0gJ9zHwZtZllCGH+HXe/O568ycymx/OnA5urVd8oeBvwLjNbSxhKO8/Mbqe22wzhb7rD3R+PH3+PEPC13u4LgDXu3unuWeBu4Heo/XbD0G18w/mWtEAv5wurE8/MjDCm+ry7f6Vk1j3AB+L7HwB+dKhrGy3ufo27z3L3OYTf6y/c/UpquM0A7r4RWGdmx8STzgeeo8bbTRhqOcPMmuK/9/MJ7xXVerth6DbeA1xmZvVmNhc4CnjigLbs7om6Eb6M+kXgJeAvql3PKLXxLMJLrWeA5fHtYqCN8K74qvjnpGrXOkrtPwf4SXy/5tsMnAIsi3/fPwQmjpF2XwusBFYA/wrU11q7gTsJ7xFkCT3wDw/XRuAv4mx7AVh4oPvTR/9FRGpE0oZcRERkCAp0EZEaoUAXEakRCnQRkRqhQBcRqREKdBGRGqFAFxGpEf8fht4UTX9gyzIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mlp with scaled outputs on the regression problem\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model using spearman_correlation los function\n",
    "#model.compile(loss=spearman_loss, optimizer=SGD(lr=0.01, momentum=0.9)) #no gradient, cannot use\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9), metrics=[spearman_metric])\n",
    "#model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9))\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=1)\n",
    "# evaluate the model\n",
    "train_mse = model.evaluate(trainX, trainy, verbose=1)\n",
    "test_mse = model.evaluate(testX, testy, verbose=1)\n",
    "#print('MSE Train: %.3f, MSE Test: %.3f' % (train_mse[0], test_mse[0])) #when using custom loss and custom metric\n",
    "print('Spearman Train: %.3f, Spearman Test: %.3f' % (train_mse[1], test_mse[1])) #when using custom loss and custom metric\n",
    "#print('Train: %.3f, Test: %.3f' % (train_mse, test_mse)) \n",
    "#plot loss during training\n",
    "pyplot.title('Loss / Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.py4u.net/discuss/199027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "@tf.custom_gradient\n",
    "def py_loss_fn(y_true, y_pred):\n",
    "  \"\"\" This function takes eager tensors as inputs which can be explicitly\n",
    "  converted to np.arrays via EagerTensor.numpy() or implicitly converted\n",
    "  by applying numpy operations to them.\n",
    "\n",
    "  However, once tf operations are no longer used it means that the function has to\n",
    "  implement its own gradient function.\n",
    "  \"\"\"\n",
    "  def grad(dy):\n",
    "    \"\"\" Compute gradients for function inputs.\n",
    "        Ignore input[0] (y_true) since that is model.targets[0]\n",
    "    \"\"\"\n",
    "    g = np.mean(-dy * np.sign(y_true - y_pred), axis=1)[:, np.newaxis]\n",
    "    return None, g\n",
    "\n",
    "  return np.mean(np.abs(y_true - y_pred), axis=1), grad\n",
    "\n",
    "def eager_loss_fn(y_true, y_pred):\n",
    "  \"\"\" If tf operations are used on eager tensors auto diff works without issues\n",
    "  \"\"\"\n",
    "  return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "\n",
    "def loss_fn(y_true, y_pred, **kw_args):\n",
    "  \"\"\" This function takes tensors as inputs. Numpy operations are not valid.\n",
    "  \"\"\"\n",
    "#   loss = tf.py_function(eager_loss_fn, inp=[y_true, y_pred], Tout=tf.float32)\n",
    "  \n",
    "  loss = tf.py_function(py_loss_fn, inp=[y_true, y_pred], Tout=tf.float32)\n",
    "\n",
    "  return loss\n",
    "\n",
    "def make_model():\n",
    "  \"\"\" Linear regression model with custom loss \"\"\"\n",
    "  inp = Input(shape=(4,))\n",
    "  out = Dense(1, use_bias=False)(inp)\n",
    "  model = Model(inp, out)\n",
    "  model.compile('adam', loss_fn)\n",
    "  return model\n",
    "\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.077617883682251\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "FACTORS = np.arange(4) + 1\n",
    "def test_fn(x):\n",
    "  return np.dot(x, FACTORS.T)\n",
    "\n",
    "X = np.random.rand(3, 4)\n",
    "Y = np.apply_along_axis(test_fn, 1, X)\n",
    "\n",
    "history = model.fit(X, Y, epochs=1000, verbose=False)\n",
    "print(history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/aponte411/numerai_train/blob/master/metrics.py\n",
    "https://pretagteam.com/question/how-to-compute-spearman-correlation-in-tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
