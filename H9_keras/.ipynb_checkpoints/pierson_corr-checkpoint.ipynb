{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "import keras.backend as K\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pierson_loss(y_true, y_pred):\n",
    "    \"\"\"Pearson correlation coefficient\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "    \n",
    "    return 1 - K.square(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "penalized_pierson_loss is a function that maximizes the pearson correlation coefficient between the predicted values and the labels, while trying to have the same mean and variance.  It is the same as pierson_loss except for the addition of a penalty term (0.01*sqdif): https://colab.research.google.com/github/stoerr/machinelearning-tensorflow/blob/master/published/CorrelationLossTest.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalized_pierson_loss(x,y, axis=-2):\n",
    "    \"\"\"Penalized Pearson correlation coefficient\"\"\"\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    y = K.cast(y, x.dtype)\n",
    "    n = tf.cast(tf.shape(x)[axis], x.dtype)\n",
    "    xsum = tf.reduce_sum(x, axis=axis)\n",
    "    ysum = tf.reduce_sum(y, axis=axis)\n",
    "    xmean = xsum / n\n",
    "    ymean = ysum / n\n",
    "    xsqsum = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n",
    "    ysqsum = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n",
    "    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n",
    "    corr = cov / (tf.sqrt(xsqsum * ysqsum)+ K.epsilon())\n",
    "    sqdif = tf.reduce_sum(tf.math.squared_difference(x, y), axis=axis) / n / tf.sqrt(ysqsum / n)\n",
    "    return tf.convert_to_tensor( K.mean(tf.constant(1.0, dtype=x.dtype) - corr + (0.01 * sqdif)) , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pierson_metric(y_true, y_pred):\n",
    "    \"\"\"Pearson correlation coefficient\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "    \n",
    "    return 1 - K.square(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=num_features, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainX)\n",
    "# transform training dataset\n",
    "trainX = scaler.transform(trainX)\n",
    "# transform test dataset\n",
    "testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 342us/step - loss: 0.9231 - pierson_metric: 0.9231 - val_loss: 0.9172 - val_pierson_metric: 0.9172\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.7357 - pierson_metric: 0.7357 - val_loss: 0.4380 - val_pierson_metric: 0.4380\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.3083 - pierson_metric: 0.3083 - val_loss: 0.1855 - val_pierson_metric: 0.1855\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.1588 - pierson_metric: 0.1588 - val_loss: 0.1259 - val_pierson_metric: 0.1259\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.1133 - pierson_metric: 0.1133 - val_loss: 0.1034 - val_pierson_metric: 0.1034\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0945 - pierson_metric: 0.0945 - val_loss: 0.0893 - val_pierson_metric: 0.0893\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0745 - pierson_metric: 0.0745 - val_loss: 0.0785 - val_pierson_metric: 0.0785\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0662 - pierson_metric: 0.0662 - val_loss: 0.0695 - val_pierson_metric: 0.0695\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0583 - pierson_metric: 0.0583 - val_loss: 0.0623 - val_pierson_metric: 0.0623\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0505 - pierson_metric: 0.0505 - val_loss: 0.0574 - val_pierson_metric: 0.0574\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0466 - pierson_metric: 0.0466 - val_loss: 0.0521 - val_pierson_metric: 0.0521\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0413 - pierson_metric: 0.0413 - val_loss: 0.0479 - val_pierson_metric: 0.0479\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0367 - pierson_metric: 0.0367 - val_loss: 0.0447 - val_pierson_metric: 0.0447\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0328 - pierson_metric: 0.0328 - val_loss: 0.0422 - val_pierson_metric: 0.0422\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0315 - pierson_metric: 0.0315 - val_loss: 0.0399 - val_pierson_metric: 0.0399\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0278 - pierson_metric: 0.0278 - val_loss: 0.0380 - val_pierson_metric: 0.0380\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0277 - pierson_metric: 0.0277 - val_loss: 0.0359 - val_pierson_metric: 0.0359\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0261 - pierson_metric: 0.0261 - val_loss: 0.0341 - val_pierson_metric: 0.0341\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.0233 - pierson_metric: 0.0233 - val_loss: 0.0326 - val_pierson_metric: 0.0326\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0230 - pierson_metric: 0.0230 - val_loss: 0.0309 - val_pierson_metric: 0.0309\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0218 - pierson_metric: 0.0218 - val_loss: 0.0297 - val_pierson_metric: 0.0297\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0202 - pierson_metric: 0.0202 - val_loss: 0.0285 - val_pierson_metric: 0.0285\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0188 - pierson_metric: 0.0188 - val_loss: 0.0274 - val_pierson_metric: 0.0274\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0183 - pierson_metric: 0.0183 - val_loss: 0.0265 - val_pierson_metric: 0.0265\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0181 - pierson_metric: 0.0181 - val_loss: 0.0259 - val_pierson_metric: 0.0259\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0173 - pierson_metric: 0.0173 - val_loss: 0.0248 - val_pierson_metric: 0.0248\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0156 - pierson_metric: 0.0156 - val_loss: 0.0239 - val_pierson_metric: 0.0239\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0156 - pierson_metric: 0.0156 - val_loss: 0.0231 - val_pierson_metric: 0.0231\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0147 - pierson_metric: 0.0147 - val_loss: 0.0225 - val_pierson_metric: 0.0225\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0143 - pierson_metric: 0.0143 - val_loss: 0.0221 - val_pierson_metric: 0.0221\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0135 - pierson_metric: 0.0135 - val_loss: 0.0215 - val_pierson_metric: 0.0215\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0135 - pierson_metric: 0.0135 - val_loss: 0.0209 - val_pierson_metric: 0.0209\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0130 - pierson_metric: 0.0130 - val_loss: 0.0204 - val_pierson_metric: 0.0204\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0129 - pierson_metric: 0.0129 - val_loss: 0.0199 - val_pierson_metric: 0.0199\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0122 - pierson_metric: 0.0122 - val_loss: 0.0194 - val_pierson_metric: 0.0194\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0110 - pierson_metric: 0.0110 - val_loss: 0.0188 - val_pierson_metric: 0.0188\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0110 - pierson_metric: 0.0110 - val_loss: 0.0184 - val_pierson_metric: 0.0184\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0112 - pierson_metric: 0.0112 - val_loss: 0.0180 - val_pierson_metric: 0.0180\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0106 - pierson_metric: 0.0106 - val_loss: 0.0177 - val_pierson_metric: 0.0177\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0099 - pierson_metric: 0.0099 - val_loss: 0.0173 - val_pierson_metric: 0.0173\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0098 - pierson_metric: 0.0098 - val_loss: 0.0170 - val_pierson_metric: 0.0170\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0097 - pierson_metric: 0.0097 - val_loss: 0.0166 - val_pierson_metric: 0.0166\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0094 - pierson_metric: 0.0094 - val_loss: 0.0164 - val_pierson_metric: 0.0164\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0097 - pierson_metric: 0.0097 - val_loss: 0.0160 - val_pierson_metric: 0.0160\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0087 - pierson_metric: 0.0087 - val_loss: 0.0158 - val_pierson_metric: 0.0158\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0090 - pierson_metric: 0.0090 - val_loss: 0.0156 - val_pierson_metric: 0.0156\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0086 - pierson_metric: 0.0086 - val_loss: 0.0152 - val_pierson_metric: 0.0152\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0078 - pierson_metric: 0.0078 - val_loss: 0.0150 - val_pierson_metric: 0.0150\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0082 - pierson_metric: 0.0082 - val_loss: 0.0148 - val_pierson_metric: 0.0148\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0086 - pierson_metric: 0.0086 - val_loss: 0.0145 - val_pierson_metric: 0.0145\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0081 - pierson_metric: 0.0081 - val_loss: 0.0143 - val_pierson_metric: 0.0143\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0078 - pierson_metric: 0.0078 - val_loss: 0.0141 - val_pierson_metric: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0077 - pierson_metric: 0.0077 - val_loss: 0.0141 - val_pierson_metric: 0.0141\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0082 - pierson_metric: 0.0082 - val_loss: 0.0139 - val_pierson_metric: 0.0139\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0076 - pierson_metric: 0.0076 - val_loss: 0.0137 - val_pierson_metric: 0.0137\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0071 - pierson_metric: 0.0071 - val_loss: 0.0134 - val_pierson_metric: 0.0134\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0073 - pierson_metric: 0.0073 - val_loss: 0.0133 - val_pierson_metric: 0.0133\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0068 - pierson_metric: 0.0068 - val_loss: 0.0132 - val_pierson_metric: 0.0132\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.0067 - pierson_metric: 0.0067 - val_loss: 0.0130 - val_pierson_metric: 0.0130\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0068 - pierson_metric: 0.0068 - val_loss: 0.0129 - val_pierson_metric: 0.0129\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0061 - pierson_metric: 0.0061 - val_loss: 0.0128 - val_pierson_metric: 0.0128\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0063 - pierson_metric: 0.0063 - val_loss: 0.0126 - val_pierson_metric: 0.0126\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0065 - pierson_metric: 0.0065 - val_loss: 0.0125 - val_pierson_metric: 0.0125\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0061 - pierson_metric: 0.0061 - val_loss: 0.0124 - val_pierson_metric: 0.0124\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0062 - pierson_metric: 0.0062 - val_loss: 0.0122 - val_pierson_metric: 0.0122\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0061 - pierson_metric: 0.0061 - val_loss: 0.0121 - val_pierson_metric: 0.0121\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0059 - pierson_metric: 0.0059 - val_loss: 0.0120 - val_pierson_metric: 0.0120\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0061 - pierson_metric: 0.0061 - val_loss: 0.0120 - val_pierson_metric: 0.0120\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0057 - pierson_metric: 0.0057 - val_loss: 0.0119 - val_pierson_metric: 0.0119\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0060 - pierson_metric: 0.0060 - val_loss: 0.0118 - val_pierson_metric: 0.0118\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0058 - pierson_metric: 0.0058 - val_loss: 0.0117 - val_pierson_metric: 0.0117\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0057 - pierson_metric: 0.0057 - val_loss: 0.0116 - val_pierson_metric: 0.0116\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0056 - pierson_metric: 0.0056 - val_loss: 0.0114 - val_pierson_metric: 0.0114\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0054 - pierson_metric: 0.0054 - val_loss: 0.0114 - val_pierson_metric: 0.0114\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0052 - pierson_metric: 0.0052 - val_loss: 0.0113 - val_pierson_metric: 0.0113\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0053 - pierson_metric: 0.0053 - val_loss: 0.0112 - val_pierson_metric: 0.0112\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0053 - pierson_metric: 0.0053 - val_loss: 0.0111 - val_pierson_metric: 0.0111\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0052 - pierson_metric: 0.0052 - val_loss: 0.0110 - val_pierson_metric: 0.0110\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0053 - pierson_metric: 0.0053 - val_loss: 0.0109 - val_pierson_metric: 0.0109\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0053 - pierson_metric: 0.0053 - val_loss: 0.0108 - val_pierson_metric: 0.0108\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0050 - pierson_metric: 0.0050 - val_loss: 0.0107 - val_pierson_metric: 0.0107\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0050 - pierson_metric: 0.0050 - val_loss: 0.0107 - val_pierson_metric: 0.0107\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0048 - pierson_metric: 0.0048 - val_loss: 0.0106 - val_pierson_metric: 0.0106\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0048 - pierson_metric: 0.0048 - val_loss: 0.0106 - val_pierson_metric: 0.0106\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0048 - pierson_metric: 0.0048 - val_loss: 0.0105 - val_pierson_metric: 0.0105\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0050 - pierson_metric: 0.0050 - val_loss: 0.0104 - val_pierson_metric: 0.0104\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0051 - pierson_metric: 0.0051 - val_loss: 0.0104 - val_pierson_metric: 0.0104\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0045 - pierson_metric: 0.0045 - val_loss: 0.0103 - val_pierson_metric: 0.0103\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0048 - pierson_metric: 0.0048 - val_loss: 0.0103 - val_pierson_metric: 0.0103\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0047 - pierson_metric: 0.0047 - val_loss: 0.0102 - val_pierson_metric: 0.0102\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0045 - pierson_metric: 0.0045 - val_loss: 0.0101 - val_pierson_metric: 0.0101\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0046 - pierson_metric: 0.0046 - val_loss: 0.0101 - val_pierson_metric: 0.0101\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0045 - pierson_metric: 0.0045 - val_loss: 0.0100 - val_pierson_metric: 0.0100\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0043 - pierson_metric: 0.0043 - val_loss: 0.0100 - val_pierson_metric: 0.0100\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0044 - pierson_metric: 0.0044 - val_loss: 0.0099 - val_pierson_metric: 0.0099\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.0044 - pierson_metric: 0.0044 - val_loss: 0.0099 - val_pierson_metric: 0.0099\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.0043 - pierson_metric: 0.0043 - val_loss: 0.0098 - val_pierson_metric: 0.0098\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0042 - pierson_metric: 0.0042 - val_loss: 0.0098 - val_pierson_metric: 0.0098\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0044 - pierson_metric: 0.0044 - val_loss: 0.0098 - val_pierson_metric: 0.0098\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.0044 - pierson_metric: 0.0044 - val_loss: 0.0097 - val_pierson_metric: 0.0097\n",
      "500/500 [==============================] - 0s 14us/step\n",
      "500/500 [==============================] - 0s 14us/step\n",
      "Train mse: 0.004, Test mse: 0.010\n",
      "Train corr_e: 0.004, Test corr_e: 0.010\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mlp with scaled inputs outputs on the regression problem\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model using custom loss and metric functions\n",
    "model.compile(loss=pierson_loss, optimizer=SGD(lr=0.01, momentum=0.9), metrics=[pierson_metric])\n",
    "#model.compile(loss=penalized_pierson_loss, optimizer=SGD(lr=0.01, momentum=0.9), metrics=[pierson_metric])\n",
    "#model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9))\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=1)\n",
    "# evaluate the model\n",
    "train_e = model.evaluate(trainX, trainy, verbose=1)\n",
    "test_e = model.evaluate(testX, testy, verbose=1)\n",
    "print('Train mse: %.3f, Test mse: %.3f' % (train_e[0], test_e[0])) #when using custom loss and custom metric\n",
    "print('Train corr_e: %.3f, Test corr_e: %.3f' % (train_e[1], test_e[1])) #when using custom loss and custom metric\n",
    "#print('Train mse: %.3f, Test mse: %.3f' % (train_e, test_e)) \n",
    "#plot loss during training\n",
    "plt.title('Loss / Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/aponte411/numerai_train/blob/master/metrics.py\n",
    "https://pretagteam.com/question/how-to-compute-spearman-correlation-in-tensorflow\n",
    "https://www.py4u.net/discuss/199027\n",
    "https://colab.research.google.com/github/stoerr/machinelearning-tensorflow/blob/master/published/CorrelationLossTest.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
