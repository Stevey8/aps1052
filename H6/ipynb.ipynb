{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic pca denoise wrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import functions as ff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fAux\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "np.random.seed(1) #to fix the results\n",
    "rs = 3\n",
    " \n",
    "#file_path = 'outputfile.txt'\n",
    "#sys.stdout = open(file_path, \"w\")\n",
    "\n",
    "#we define this ourselves to correct the division by zero error\n",
    "def single_autocorr(series, lag):\n",
    "    s1 = series[lag:]\n",
    "    s2 = series[:-lag]\n",
    "    ms1 = np.mean(s1)\n",
    "    ms2 = np.mean(s2)\n",
    "    ds1 = s1 - ms1\n",
    "    ds2 = s2 - ms2\n",
    "    divider = np.sqrt(np.sum(ds1 * ds1)) * np.sqrt(np.sum(ds2 * ds2))\n",
    "    return np.sum(ds1 * ds2) / divider if divider != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('EURUSD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "#df = pd.read_csv('GBPUSD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "#df = pd.read_csv('NZDUSD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "df = pd.read_csv('USDCAD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "#df = pd.read_csv('USDCHF_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "\n",
    "df['<DATETIME>'] = pd.to_datetime(df['<DATE>'] + ' ' + df['<TIME>'])\n",
    "df = df.set_index('<DATETIME>')\n",
    "df.drop(['<TIME>'], axis=1, inplace=True)\n",
    "df.drop(['<DATE>'], axis=1, inplace=True)\n",
    "\n",
    "#save the open for white reality check\n",
    "openp = df['<OPEN>'].copy() #for the case we want to enter trades at the open\n",
    "\n",
    "\n",
    "#buld window features:\n",
    "for n in list(range(1,10)):  #use 5 instead of 21 because it takes a long time\n",
    "    name = 'ret' + str(n)\n",
    "    df[name] = df[\"<OPEN>\"].pct_change(periods=n) #for trading with open\n",
    "    \n",
    "\n",
    "#new window features\n",
    "df['autocorr1']=df['ret1'].rolling(50).apply(lambda s:single_autocorr(s, lag=1)).fillna(0)\n",
    "lg=3\n",
    "df['vratio']=df['ret1'].rolling(100*lg).apply(lambda s: ff.vratio(np.log(s.values), lag=lg, cor='hom')[0]).fillna(0)\n",
    "\n",
    "#build date-time features\n",
    "df[\"hour\"] = df.index.hour.values\n",
    "df[\"day\"] = df.index.dayofweek.values\n",
    "\n",
    "#build target assuming we know today's open\n",
    "df['retFut1'] = df['<OPEN>'].pct_change(1).shift(-1).fillna(0) #if you enter the trade immediately after the open\n",
    "\n",
    "#df = np.log(df+1)\n",
    "\n",
    "#transform the target\n",
    "df['retFut1_categ'] = np.where((df['retFut1'] > 0), 1, 0)\n",
    "\n",
    "#Since we are trading right after the open, \n",
    "#we only know yesterday's  high low close volume spread etc.\n",
    "df['<HIGH>'] = df['<HIGH>'].shift(1)\n",
    "df['<LOW>'] = df['<LOW>'].shift(1)\n",
    "df['<CLOSE>'] = df['<CLOSE>'].shift(1)\n",
    "df['<VOL>'] = df['<VOL>'].shift(1)\n",
    "df['<SPREAD>'] = df['<SPREAD>'].shift(1)\n",
    "\n",
    "#select the features (by dropping)\n",
    "cols_to_drop = [\"<OPEN>\",\"<HIGH>\",\"<LOW>\",\"<CLOSE>\",\"<TICKVOL>\",\"<VOL>\",\"<SPREAD>\"]  #optional\n",
    "df_filtered = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "#distribute the df data into X inputs and y target\n",
    "X = df_filtered.drop(['retFut1', 'retFut1_categ'], axis=1) \n",
    "y = df_filtered[['retFut1_categ']]\n",
    "\n",
    "#select the samples\n",
    "x_train = X.iloc[0:10000]\n",
    "x_test = X.iloc[10000:12000]\n",
    "\n",
    "y_train = y.iloc[0:10000]\n",
    "y_test = y.iloc[10000:12000]\n",
    "\n",
    "df_train = df_filtered.iloc[0:10000]\n",
    "df_test = df_filtered.iloc[10000:12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer \n",
    "import phik\n",
    "from phik.report import plot_correlation_matrix\n",
    "from scipy.special import ndtr\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import detrendPrice \n",
    "import WhiteRealityCheckFor1 \n",
    "\n",
    "def phi_k(y_true, y_pred):\n",
    "    dfc = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
    "    try:\n",
    "        phi_k_corr = dfc.phik_matrix(interval_cols=[]).iloc[1,0]\n",
    "        phi_k_sig  = dfc.significance_matrix(interval_cols=[]).iloc[1,0]\n",
    "        phi_k_p_val = 1 - ndtr(phi_k_sig) \n",
    "    except:\n",
    "        phi_k_corr = 0\n",
    "        phi_k_p_val = 0\n",
    "    print(phi_k_p_val)\n",
    "    return phi_k_corr\n",
    "\n",
    "class CustomPCA(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components=2):\n",
    "        self.n_components = n_components\n",
    "        self.pca = PCA(n_components=self.n_components)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.pca.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.pca.inverse_transform(self.pca.fit_transform(X))\n",
    "\n",
    "\n",
    "#myscorer = None #use default accuracy score\n",
    "myscorer = make_scorer(phi_k, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTRUCTIONS\n",
    "Normally, PCA() in the pipeline will do feature extraction (with fit_transform(X)).  \n",
    "To make PCA()in the pipeline to do feature reconstruction, requires a CustomPCA()  \n",
    "(with inverse_transform(self.pca.fit_transform(X))).  \n",
    "Please have a look at the CustomPCA() function.  \n",
    "Below, if FeatureExtraction is set to True, PCA() will do feature extraction.  \n",
    "If FeatureExtraction is set to False, CustomPCA() will do feature reconstruction.  \n",
    "Open logistic_pca_denoise_WRC_results_incomplete.txt  \n",
    "Note that we already ran this script with FeatureExtraction set to True.  \n",
    "Run this script with FeatureExtraction set to False and   \n",
    "record the missing out-of-sample result.  \n",
    "Read and understand the comment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret1         float64\n",
      "ret2         float64\n",
      "ret3         float64\n",
      "ret4         float64\n",
      "ret5         float64\n",
      "ret6         float64\n",
      "ret7         float64\n",
      "ret8         float64\n",
      "ret9         float64\n",
      "autocorr1    float64\n",
      "vratio       float64\n",
      "hour           int32\n",
      "day            int32\n",
      "dtype: object\n",
      "0.3955987653630698\n",
      "9.36290188713329e-08\n",
      "0.05927867659787367\n",
      "1.6920292376099155e-06\n",
      "0.01581904423464653\n",
      "1.7871628213872448e-05\n",
      "0.1615074330522046\n",
      "9.344979067460457e-06\n",
      "0.028884072046119202\n",
      "1.3046182661957673e-06\n",
      "0.003888649305041403\n",
      "3.3323617552039053e-06\n",
      "0.0880491486474333\n",
      "7.72768877776997e-08\n",
      "0.0415642581038308\n",
      "4.095265382364488e-08\n",
      "0.16035656464490589\n",
      "8.276759277947576e-08\n",
      "0.02869744893213244\n",
      "5.501101574267864e-09\n",
      "0.059277264873192737\n",
      "0.006931152375794447\n",
      "0.16021637197221061\n",
      "0.00515000821968703\n",
      "0.04838546355018125\n",
      "2.9936835925337135e-05\n",
      "0.8235591567762578\n",
      "0.0002028073112664286\n",
      "0.005592159833844312\n",
      "0.0004333337391624337\n",
      "0.1616301238312593\n",
      "3.407431363466884e-05\n",
      "0.2062118186442765\n",
      "0.00045623921108839394\n",
      "0.1334877863598274\n",
      "2.571990273858571e-05\n",
      "0.22274245680409277\n",
      "1.5693360012170032e-05\n",
      "0.00505211495867941\n",
      "0.00020582075017128165\n",
      "0.12362489840048352\n",
      "1.3530110047788035e-05\n",
      "0.03829439349866648\n",
      "4.7585482005341184e-05\n",
      "0.005517296185452825\n",
      "8.382820949615066e-07\n",
      "0.136657515572985\n",
      "3.1624332719193404e-06\n",
      "0.0024130510663278315\n",
      "0.0007058072488473899\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0.1143278202892477\n",
      "1.2095147838842024e-07\n",
      "0.007605522638990281\n",
      "2.622953787723148e-06\n",
      "0.05074847355384826\n",
      "2.195862891052336e-05\n",
      "0.055825025461087696\n",
      "8.07634888966291e-08\n",
      "0.11289540023971445\n",
      "9.148217749999077e-08\n",
      "0.01158999293293983\n",
      "1.769642120397208e-06\n",
      "0.0502812968681281\n",
      "5.298224252214823e-06\n",
      "0.04766075763413746\n",
      "2.2809241750909592e-07\n",
      "0.004833769993536796\n",
      "2.3181242395642343e-06\n",
      "0.016221385803876998\n",
      "8.127827466619664e-08\n",
      "0.012750349367271263\n",
      "1.8621992430301049e-06\n",
      "0.05531804664114681\n",
      "4.18251496547839e-06\n",
      "0.04541859461040998\n",
      "2.2431752599860744e-07\n",
      "0.001095162967463481\n",
      "2.359435575027824e-06\n",
      "0.00673643981471117\n",
      "7.383663136462104e-08\n",
      "Best parameters : {'preprocessor__num__pca__n_components': 6, 'logistic__penalty': 'l2', 'logistic__C': 1.1288378916846895}\n",
      "Best cross-validation score : 7.75\n"
     ]
    }
   ],
   "source": [
    "FeatureExtraction=False\n",
    "if FeatureExtraction==True: ##FeatureExtraction (and Denoising) --> uncorrelated predictors\n",
    "    numeric_sub_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca',  PCA())])\n",
    "else: #FeatureReconstruction (Denoising only)\n",
    "        numeric_sub_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca',  CustomPCA())])\n",
    "\n",
    "    \n",
    "categorical_sub_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "print(x_train.dtypes)\n",
    "numeric_features_ix = x_train.select_dtypes(include=['float64']).columns\n",
    "categorical_features_ix = x_train.select_dtypes(include=['int64']).columns\n",
    "\n",
    "#Note: transformer 3-element tuples can be: ('name', function or pipeline, column_number_list or column_index)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_sub_pipeline, numeric_features_ix),\n",
    "        ('cat', categorical_sub_pipeline, categorical_features_ix)], remainder='passthrough')\n",
    "\n",
    "\n",
    "logistic = LogisticRegression(max_iter=1000, solver='liblinear') \n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),('logistic', logistic)])\n",
    "\n",
    "\n",
    "ncomponents_rs =   list(range(2,len(numeric_features_ix.values)))\n",
    "c_rs = np.logspace(3, -4, num=20, endpoint = True)\n",
    "#penalty type=L2 like ridge regression (small coefficients preferred), L1 like lasso  (coefficients can become zero)\n",
    "p_rs= [\"l1\", \"l2\"]\n",
    "\n",
    "\n",
    "param_grid =  [{'preprocessor__num__pca__n_components':ncomponents_rs, 'logistic__C': c_rs, 'logistic__penalty': p_rs}]\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipe, param_grid, cv=5, scoring=myscorer, return_train_score=True, random_state=rs)\n",
    "#grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring=myscorer, return_train_score=True)\n",
    "\n",
    "grid_search.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "best_parameters = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "print(\"Best parameters : {}\".format(best_parameters))\n",
    "#print('Best estimator {}'.format(best_model))\n",
    "print(\"Best cross-validation score : {:.2f}\".format(grid_search.best_score_*100))\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "#print(results.T)\n",
    "results.to_csv(\"results_logisticreg.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-sample: CAGR=0.0159059 Sharpe ratio=0.631392 maxDD=-0.0617796 maxDDD=810 Calmar ratio=0.257462\n",
      "\n",
      "Out-of-sample: CAGR=0.0406631 Sharpe ratio=1.24685 maxDD=-0.0357181 maxDDD=246 Calmar ratio=1.13844  phi_k_corr=0.150482 phi_k_p_val=7.814e-06  accuracy_score=0.551\n",
      "\n",
      "Ljung-Box test p-value 3.3764775759555387e-31\n",
      "average return 0.002232\n",
      "[-0.00277226  0.00274753]\n",
      "Do not reject Ho = The population distribution of rule returns has an expected value of zero or less (because p_value is not small enough)\n",
      "p_value:\n",
      "0.05800000000000005\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "# Make \"predictions\" on training set (in-sample)\n",
    "#positions = np.where(best_model.predict(x_train)> 0,1,-1 )\n",
    "positions = np.where(grid_search.predict(x_train)> 0,1,-1 ) #POSITIONS\n",
    "\n",
    "\n",
    "dailyRet = pd.Series(positions).fillna(0).values * df_train.retFut1 #for trading right after the open\n",
    "\n",
    "dailyRet = dailyRet.fillna(0)\n",
    "\n",
    "cumret = np.cumprod(dailyRet + 1) - 1\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(cumret.index, cumret)\n",
    "plt.title('Cross-validated LogisticRegression on currency: train set')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.xlabel('Date')\n",
    "#plt.show()\n",
    "plt.savefig(r'Results\\%s.png' %(\"TrainCumulative\"))\n",
    "\n",
    "\n",
    "cagr = (1 + cumret[-1]) ** (252 / len(cumret)) - 1\n",
    "maxDD, maxDDD = fAux.calculateMaxDD(cumret)\n",
    "ratio = (252.0 ** (1.0/2.0)) * np.mean(dailyRet) / np.std(dailyRet)\n",
    "print (('In-sample: CAGR={:0.6} Sharpe ratio={:0.6} maxDD={:0.6} maxDDD={:d} Calmar ratio={:0.6}\\n'\\\n",
    ").format(cagr, ratio, maxDD, maxDDD.astype(int), -cagr/maxDD))\n",
    "\n",
    "# Test set\n",
    "# Make \"predictions\" on test set (out-of-sample)\n",
    "\n",
    "#positions2 = np.where(best_model.predict(x_test)> 0,1,-1 )\n",
    "positions2 = np.where(grid_search.predict(x_test)> 0,1,-1 ) #POSITIONS\n",
    "\n",
    "\n",
    "dailyRet2 = pd.Series(positions2).fillna(0).values * df_test.retFut1 #for trading right after the open\n",
    "dailyRet2 = dailyRet2.fillna(0)\n",
    "\n",
    "cumret2 = np.cumprod(dailyRet2 + 1) - 1\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(cumret2.index, cumret2)\n",
    "title = 'Cross-validated LogisticRegression on currency: test set'\n",
    "plt.title(title)\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.xlabel('Date')\n",
    "#plt.show()\n",
    "plt.savefig(r'Results\\%s.png' %(\"TestCumulative\"))\n",
    "\n",
    "#metrics\n",
    "accuracy_score = accuracy_score(y_test.values.ravel(), grid_search.predict(x_test))\n",
    "\n",
    "#If this figure does not plot correctly select the lines and press F9 again\n",
    "arr1 = y_test.values.ravel()\n",
    "arr2 = grid_search.predict(x_test)\n",
    "dfc = pd.DataFrame({'y_true': arr1, 'y_pred': arr2})\n",
    "phi_k_corr = dfc.phik_matrix(interval_cols=[]).iloc[1,0]\n",
    "significance_overview = dfc.significance_matrix(interval_cols=[])\n",
    "phi_k_sig  = dfc.significance_matrix(interval_cols=[]).iloc[1,0]\n",
    "phi_k_p_val = 1 - ndtr(phi_k_sig) \n",
    "plot_correlation_matrix(significance_overview.fillna(0).values, \n",
    "                        x_labels=significance_overview.columns, \n",
    "                        y_labels=significance_overview.index, \n",
    "                        vmin=-5, vmax=5, title=\"Significance of the coefficients\", \n",
    "                        usetex=False, fontsize_factor=1.5, figsize=(7, 5))\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(r'Results\\%s.png' %(\"PhikSignificance\"))\n",
    "\n",
    "cagr = (1 + cumret2[-1]) ** (252 / len(cumret2)) - 1\n",
    "maxDD, maxDDD = fAux.calculateMaxDD(cumret2)\n",
    "ratio = (252.0 ** (1.0/2.0)) * np.mean(dailyRet2) / np.std(dailyRet2)\n",
    "print (('Out-of-sample: CAGR={:0.6} Sharpe ratio={:0.6} maxDD={:0.6} maxDDD={:d} Calmar ratio={:0.6}  phi_k_corr={:0.6} phi_k_p_val={:0.6}  accuracy_score={:0.6}\\n'\\\n",
    ").format(cagr, ratio, maxDD, maxDDD.astype(int), -cagr/maxDD, phi_k_corr, phi_k_p_val, accuracy_score))\n",
    "\n",
    "\n",
    "#plot the residuals\n",
    "true_y = y_test.values.ravel()\n",
    "pred_y = grid_search.predict(x_test)\n",
    "residuals = np.subtract(true_y, pred_y)\n",
    "\n",
    "from scipy.stats import norm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(14,4))\n",
    "sns.distplot(residuals, fit=norm, ax=axes[0], axlabel='Residuals', label='Residuals')\n",
    "axes[0].set_title('Residual Distribution')\n",
    "axes[0].legend()\n",
    "plot_acf(residuals, lags=10, zero=False, ax=axes[1], title='Residual Autocorrelation')\n",
    "axes[1].set_xlabel('Lags')\n",
    "sns.despine()\n",
    "fig.tight_layout();\n",
    "#plt.show()\n",
    "plt.savefig(r'Results\\%s.png' %(\"ResidualDistribution\"))\n",
    "plt.close(\"all\")\n",
    "\n",
    "#Residual autocorrelation\n",
    "#If the p-value of the test is greater than the required significance (>0.05), residuals are independent\n",
    "import statsmodels.api as sm\n",
    "lb = sm.stats.acorr_ljungbox(residuals, lags=[10], boxpierce=False)\n",
    "print(\"Ljung-Box test p-value\", lb.iloc[0,1])\n",
    "\n",
    "#Detrending Prices and Returns and white reality check\n",
    "detrended_open = detrendPrice.detrendPrice(openp[10000:12000])\n",
    "detrended_retFut1 = detrended_open.pct_change(periods=1).shift(-1).fillna(0)\n",
    "detrended_syst_rets = detrended_retFut1 * pd.Series(positions2).fillna(0)\n",
    "WhiteRealityCheckFor1.bootstrap(detrended_syst_rets)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic pca wrc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import functions as ff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fAux\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "np.random.seed(1) #to fix the results\n",
    " \n",
    "#file_path = 'outputfile.txt'\n",
    "#sys.stdout = open(file_path, \"w\")\n",
    "\n",
    "#we define this ourselves to correct the division by zero error\n",
    "def single_autocorr(series, lag):\n",
    "    s1 = series[lag:]\n",
    "    s2 = series[:-lag]\n",
    "    ms1 = np.mean(s1)\n",
    "    ms2 = np.mean(s2)\n",
    "    ds1 = s1 - ms1\n",
    "    ds2 = s2 - ms2\n",
    "    divider = np.sqrt(np.sum(ds1 * ds1)) * np.sqrt(np.sum(ds2 * ds2))\n",
    "    return np.sum(ds1 * ds2) / divider if divider != 0 else 0\n",
    "\n",
    "#df = pd.read_csv('EURUSD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "#df = pd.read_csv('GBPUSD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "#df = pd.read_csv('NZDUSD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "df = pd.read_csv('USDCAD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "#df = pd.read_csv('USDCHF_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "\n",
    "df['<DATETIME>'] = pd.to_datetime(df['<DATE>'] + ' ' + df['<TIME>'])\n",
    "df = df.set_index('<DATETIME>')\n",
    "df.drop(['<TIME>'], axis=1, inplace=True)\n",
    "df.drop(['<DATE>'], axis=1, inplace=True)\n",
    "\n",
    "#save the open for white reality check\n",
    "openp = df['<OPEN>'].copy() #for the case we want to enter trades at the open\n",
    "\n",
    "\n",
    "#buld window features:\n",
    "for n in list(range(1,10)):  #use 5 instead of 21 because it takes a long time\n",
    "    name = 'ret' + str(n)\n",
    "    df[name] = df[\"<OPEN>\"].pct_change(periods=n) #for trading with open\n",
    "   \n",
    "\n",
    "#new window features\n",
    "df['autocorr1']=df['ret1'].rolling(50).apply(lambda s:single_autocorr(s, lag=1)).fillna(0)\n",
    "lg=3\n",
    "df['vratio']=df['ret1'].rolling(100*lg).apply(lambda s: ff.vratio(np.log(s.values), lag=lg, cor='hom')[0]).fillna(0)\n",
    "\n",
    "#build date-time features\n",
    "df[\"hour\"] = df.index.hour.values\n",
    "df[\"day\"] = df.index.dayofweek.values\n",
    "\n",
    "#build target assuming we know today's open\n",
    "df['retFut1'] = df['<OPEN>'].pct_change(1).shift(-1).fillna(0) #if you enter the trade immediately after the open\n",
    "\n",
    "#df = np.log(df+1)\n",
    "\n",
    "#transform the target\n",
    "df['retFut1_categ'] = np.where((df['retFut1'] > 0), 1, 0)\n",
    "\n",
    "#Since we are trading right after the open, \n",
    "#we only know yesterday's  high low close volume spread etc.\n",
    "df['<HIGH>'] = df['<HIGH>'].shift(1)\n",
    "df['<LOW>'] = df['<LOW>'].shift(1)\n",
    "df['<CLOSE>'] = df['<CLOSE>'].shift(1)\n",
    "df['<VOL>'] = df['<VOL>'].shift(1)\n",
    "df['<SPREAD>'] = df['<SPREAD>'].shift(1)\n",
    "\n",
    "#select the features (by dropping)\n",
    "cols_to_drop = [\"<OPEN>\",\"<HIGH>\",\"<LOW>\",\"<CLOSE>\",\"<TICKVOL>\",\"<VOL>\",\"<SPREAD>\"]  #optional\n",
    "df_filtered = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "#distribute the df data into X inputs and y target\n",
    "X = df_filtered.drop(['retFut1', 'retFut1_categ'], axis=1) \n",
    "y = df_filtered[['retFut1_categ']]\n",
    "\n",
    "#select the samples\n",
    "x_train = X.iloc[0:10000]\n",
    "x_test = X.iloc[10000:12000]\n",
    "\n",
    "y_train = y.iloc[0:10000]\n",
    "y_test = y.iloc[10000:12000]\n",
    "\n",
    "df_train = df_filtered.iloc[0:10000]\n",
    "df_test = df_filtered.iloc[10000:12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer \n",
    "import phik\n",
    "from phik.report import plot_correlation_matrix\n",
    "from scipy.special import ndtr\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import detrendPrice \n",
    "import WhiteRealityCheckFor1 \n",
    "\n",
    "def phi_k(y_true, y_pred):\n",
    "    dfc = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
    "    try:\n",
    "        phi_k_corr = dfc.phik_matrix(interval_cols=[]).iloc[1,0]\n",
    "        phi_k_sig  = dfc.significance_matrix(interval_cols=[]).iloc[1,0]\n",
    "        phi_k_p_val = 1 - ndtr(phi_k_sig) \n",
    "    except:\n",
    "        phi_k_corr = 0\n",
    "        phi_k_p_val = 0\n",
    "    print(phi_k_p_val)\n",
    "    return phi_k_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTRUCTIONS\n",
    "Include a step with a feature extraction device(sklearn.decomposition.PCA)  \n",
    "into the appropriate sub_pipeline, and  \n",
    "in the appropriate order (before or after scaling).    \n",
    "Call the step 'pca'.  \n",
    "PCA is documented here:  \n",
    "https://archive.is/4Cler  \n",
    "Alternatively, follow the PCA example in FeatureSelectionExtractionPipelines.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#myscorer = None #use default accuracy score\n",
    "myscorer = make_scorer(phi_k, greater_is_better=True)\n",
    "\n",
    "numeric_sub_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA())])  \n",
    "categorical_sub_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "print(x_train.dtypes)\n",
    "numeric_features_ix = x_train.select_dtypes(include=['float64']).columns\n",
    "categorical_features_ix = x_train.select_dtypes(include=['int64']).columns\n",
    "\n",
    "#Note: transformer 3-element tuples can be: ('name', function or pipeline, column_number_list or column_index)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_sub_pipeline, numeric_features_ix),\n",
    "        ('cat', categorical_sub_pipeline, categorical_features_ix)], remainder='passthrough')\n",
    "\n",
    "\n",
    "logistic = LogisticRegression(max_iter=1000, solver='liblinear') \n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),('logistic', logistic)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTRUCTIONS  \n",
    "Specify in ncomponents_rs the number of components    \n",
    "for PCA to try (from 2 to the maximum possible)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomponents_rs = list(range(2,len(numeric_features_ix.values)))\n",
    "c_rs = np.logspace(3, -4, num=20, endpoint = True)\n",
    "#penalty type=L2 like ridge regression (small coefficients preferred), L1 like lasso  (coefficients can become zero)\n",
    "p_rs= [\"l1\", \"l2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTRUCTIONS\n",
    "The tricky part is to construct the parameter grid correctly.  \n",
    "Start by proposing a key like 'preprocessor__n_components' \n",
    "(it is the wrong key but close enough)  \n",
    "You will get an error.  \n",
    "Following the instructions of the error message:  \n",
    "Print out the list of possible keys by printing out:  \n",
    "grid_search.get_params().keys()  \n",
    "Find the correct key and substitute it instead of 'preprocessor__n_components'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid =  [{, 'logistic__C': c_rs, 'logistic__penalty': p_rs}]\n",
    "param_grid =  [{'preprocessor__num__pca__n_components':ncomponents_rs, \n",
    "                'logistic__C': c_rs, 'logistic__penalty': p_rs}]\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipe, param_grid, cv=5, scoring=myscorer, return_train_score=True)\n",
    "#grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring=myscorer, return_train_score=True)\n",
    "\n",
    "grid_search.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "best_parameters = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "print(\"Best parameters : {}\".format(best_parameters))\n",
    "#print('Best estimator {}'.format(best_model))\n",
    "print(\"Best cross-validation score : {:.2f}\".format(grid_search.best_score_*100))\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "#print(results.T)\n",
    "results.to_csv(\"results_logisticreg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "# Make \"predictions\" on training set (in-sample)\n",
    "#positions = np.where(best_model.predict(x_train)> 0,1,-1 )\n",
    "positions = np.where(grid_search.predict(x_train)> 0,1,-1 ) #POSITIONS\n",
    "\n",
    "\n",
    "dailyRet = pd.Series(positions).fillna(0).values * df_train.retFut1 #for trading right after the open\n",
    "\n",
    "dailyRet = dailyRet.fillna(0)\n",
    "\n",
    "cumret = np.cumprod(dailyRet + 1) - 1\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(cumret.index, cumret)\n",
    "plt.title('Cross-validated LogisticRegression on currency: train set')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.xlabel('Date')\n",
    "#plt.show()\n",
    "plt.savefig(r'Results\\%s.png' %(\"TrainCumulative\"))\n",
    "\n",
    "\n",
    "cagr = (1 + cumret[-1]) ** (252 / len(cumret)) - 1\n",
    "maxDD, maxDDD = fAux.calculateMaxDD(cumret)\n",
    "ratio = (252.0 ** (1.0/2.0)) * np.mean(dailyRet) / np.std(dailyRet)\n",
    "print (('In-sample: CAGR={:0.6} Sharpe ratio={:0.6} maxDD={:0.6} maxDDD={:d} Calmar ratio={:0.6}\\n'\\\n",
    ").format(cagr, ratio, maxDD, maxDDD.astype(int), -cagr/maxDD))\n",
    "\n",
    "# Test set\n",
    "# Make \"predictions\" on test set (out-of-sample)\n",
    "\n",
    "#positions2 = np.where(best_model.predict(x_test)> 0,1,-1 )\n",
    "positions2 = np.where(grid_search.predict(x_test)> 0,1,-1 ) #POSITIONS\n",
    "\n",
    "\n",
    "dailyRet2 = pd.Series(positions2).fillna(0).values * df_test.retFut1 #for trading right after the open\n",
    "dailyRet2 = dailyRet2.fillna(0)\n",
    "\n",
    "cumret2 = np.cumprod(dailyRet2 + 1) - 1\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(cumret2.index, cumret2)\n",
    "title = 'Cross-validated LogisticRegression on currency: test set'\n",
    "plt.title(title)\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.xlabel('Date')\n",
    "#plt.show()\n",
    "plt.savefig(r'Results\\%s.png' %(\"TestCumulative\"))\n",
    "\n",
    "#metrics\n",
    "accuracy_score = accuracy_score(y_test.values.ravel(), grid_search.predict(x_test))\n",
    "\n",
    "#If this figure does not plot correctly select the lines and press F9 again\n",
    "arr1 = y_test.values.ravel()\n",
    "arr2 = grid_search.predict(x_test)\n",
    "dfc = pd.DataFrame({'y_true': arr1, 'y_pred': arr2})\n",
    "phi_k_corr = dfc.phik_matrix(interval_cols=[]).iloc[1,0]\n",
    "significance_overview = dfc.significance_matrix(interval_cols=[])\n",
    "phi_k_sig  = dfc.significance_matrix(interval_cols=[]).iloc[1,0]\n",
    "phi_k_p_val = 1 - ndtr(phi_k_sig) \n",
    "plot_correlation_matrix(significance_overview.fillna(0).values, \n",
    "                        x_labels=significance_overview.columns, \n",
    "                        y_labels=significance_overview.index, \n",
    "                        vmin=-5, vmax=5, title=\"Significance of the coefficients\", \n",
    "                        usetex=False, fontsize_factor=1.5, figsize=(7, 5))\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(r'Results\\%s.png' %(\"PhikSignificance\"))\n",
    "\n",
    "cagr = (1 + cumret2[-1]) ** (252 / len(cumret2)) - 1\n",
    "maxDD, maxDDD = fAux.calculateMaxDD(cumret2)\n",
    "ratio = (252.0 ** (1.0/2.0)) * np.mean(dailyRet2) / np.std(dailyRet2)\n",
    "print (('Out-of-sample: CAGR={:0.6} Sharpe ratio={:0.6} maxDD={:0.6} maxDDD={:d} Calmar ratio={:0.6}  phi_k_corr={:0.6} phi_k_p_val={:0.6}  accuracy_score={:0.6}\\n'\\\n",
    ").format(cagr, ratio, maxDD, maxDDD.astype(int), -cagr/maxDD, phi_k_corr, phi_k_p_val, accuracy_score))\n",
    "\n",
    "\n",
    "#plot the residuals\n",
    "true_y = y_test.values.ravel()\n",
    "pred_y = grid_search.predict(x_test)\n",
    "residuals = np.subtract(true_y, pred_y)\n",
    "\n",
    "from scipy.stats import norm\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(14,4))\n",
    "sns.distplot(residuals, fit=norm, ax=axes[0], axlabel='Residuals', label='Residuals')\n",
    "axes[0].set_title('Residual Distribution')\n",
    "axes[0].legend()\n",
    "plot_acf(residuals, lags=10, zero=False, ax=axes[1], title='Residual Autocorrelation')\n",
    "axes[1].set_xlabel('Lags')\n",
    "sns.despine()\n",
    "fig.tight_layout();\n",
    "#plt.show()\n",
    "plt.savefig(r'Results\\%s.png' %(\"ResidualDistribution\"))\n",
    "plt.close(\"all\")\n",
    "\n",
    "#Residual autocorrelation\n",
    "#If the p-value of the test is greater than the required significance (>0.05), residuals are independent\n",
    "import statsmodels.api as sm\n",
    "lb = sm.stats.acorr_ljungbox(residuals, lags=[10], boxpierce=False)\n",
    "print(\"Ljung-Box test p-value\", lb.iloc[0,1])\n",
    "\n",
    "#Detrending Prices and Returns and white reality check\n",
    "detrended_open = detrendPrice.detrendPrice(openp[10000:12000])\n",
    "detrended_retFut1 = detrended_open.pct_change(periods=1).shift(-1).fillna(0)\n",
    "detrended_syst_rets = detrended_retFut1 * pd.Series(positions2).fillna(0)\n",
    "WhiteRealityCheckFor1.bootstrap(detrended_syst_rets)\n",
    "plt.show()\n",
    "\n",
    "column_names = []\n",
    "num_numeric = best_parameters['preprocessor__num__pca__n_components']\n",
    "for i in range(1,num_numeric+1):\n",
    "    column_names.append('numeric_features_'+str(i))\n",
    "num_dummies = len(best_model[1].coef_.ravel().tolist())-num_numeric\n",
    "for i in range(1,num_dummies+1):\n",
    "    column_names.append('dummies_'+str(i))\n",
    "\n",
    "##plot the coefficients\n",
    "importance = pd.DataFrame(zip(best_model[1].coef_.ravel().tolist(), column_names))\n",
    "importance.columns = ['slope','feature_name']\n",
    "importance_plot = sns.barplot(x=importance['feature_name'], y=importance['slope'], data=importance,orient='v',dodge=False,order=importance.sort_values('slope',ascending=False).feature_name)\n",
    "for item in importance_plot.get_xticklabels(): #rotate the x labels by 90 degrees to avoid text overlapping\n",
    "    item.set_rotation(90)\n",
    "plt.show()\n",
    "plt.savefig(r'Results\\%s.png' %(\"Coefficients\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic svd wrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import functions as ff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fAux\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "np.random.seed(1) #to fix the results\n",
    " \n",
    "#file_path = 'outputfile.txt'\n",
    "#sys.stdout = open(file_path, \"w\")\n",
    "\n",
    "#we define this ourselves to correct the division by zero error\n",
    "def single_autocorr(series, lag):\n",
    "    s1 = series[lag:]\n",
    "    s2 = series[:-lag]\n",
    "    ms1 = np.mean(s1)\n",
    "    ms2 = np.mean(s2)\n",
    "    ds1 = s1 - ms1\n",
    "    ds2 = s2 - ms2\n",
    "    divider = np.sqrt(np.sum(ds1 * ds1)) * np.sqrt(np.sum(ds2 * ds2))\n",
    "    return np.sum(ds1 * ds2) / divider if divider != 0 else 0\n",
    "\n",
    "#df = pd.read_csv('EURUSD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "#df = pd.read_csv('GBPUSD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "#df = pd.read_csv('NZDUSD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "df = pd.read_csv('USDCAD_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "#df = pd.read_csv('USDCHF_H3_200001030000_202107201800.csv', sep='\\t')\n",
    "\n",
    "df['<DATETIME>'] = pd.to_datetime(df['<DATE>'] + ' ' + df['<TIME>'])\n",
    "df = df.set_index('<DATETIME>')\n",
    "df.drop(['<TIME>'], axis=1, inplace=True)\n",
    "df.drop(['<DATE>'], axis=1, inplace=True)\n",
    "\n",
    "#save the open for white reality check\n",
    "openp = df['<OPEN>'].copy() #for the case we want to enter trades at the open\n",
    "\n",
    "\n",
    "#buld window features:\n",
    "for n in list(range(1,10)):  #use 5 instead of 21 because it takes a long time\n",
    "    name = 'ret' + str(n)\n",
    "    df[name] = df[\"<OPEN>\"].pct_change(periods=n) #for trading with open\n",
    "    \n",
    "\n",
    "#new window features\n",
    "df['autocorr1']=df['ret1'].rolling(50).apply(lambda s:single_autocorr(s, lag=1)).fillna(0)\n",
    "lg=3\n",
    "df['vratio']=df['ret1'].rolling(100*lg).apply(lambda s: ff.vratio(np.log(s.values), lag=lg, cor='hom')[0]).fillna(0)\n",
    "\n",
    "#build date-time features\n",
    "df[\"hour\"] = df.index.hour.values\n",
    "df[\"day\"] = df.index.dayofweek.values\n",
    "\n",
    "#build target assuming we know today's open\n",
    "df['retFut1'] = df['<OPEN>'].pct_change(1).shift(-1).fillna(0) #if you enter the trade immediately after the open\n",
    "\n",
    "#df = np.log(df+1)\n",
    "\n",
    "#transform the target\n",
    "df['retFut1_categ'] = np.where((df['retFut1'] > 0), 1, 0)\n",
    "\n",
    "#Since we are trading right after the open, \n",
    "#we only know yesterday's  high low close volume spread etc.\n",
    "df['<HIGH>'] = df['<HIGH>'].shift(1)\n",
    "df['<LOW>'] = df['<LOW>'].shift(1)\n",
    "df['<CLOSE>'] = df['<CLOSE>'].shift(1)\n",
    "df['<VOL>'] = df['<VOL>'].shift(1)\n",
    "df['<SPREAD>'] = df['<SPREAD>'].shift(1)\n",
    "\n",
    "#select the features (by dropping)\n",
    "cols_to_drop = [\"<OPEN>\",\"<HIGH>\",\"<LOW>\",\"<CLOSE>\",\"<TICKVOL>\",\"<VOL>\",\"<SPREAD>\"]  #optional\n",
    "df_filtered = df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "#distribute the df data into X inputs and y target\n",
    "X = df_filtered.drop(['retFut1', 'retFut1_categ'], axis=1) \n",
    "y = df_filtered[['retFut1_categ']]\n",
    "\n",
    "#select the samples\n",
    "x_train = X.iloc[0:10000]\n",
    "x_test = X.iloc[10000:12000]\n",
    "\n",
    "y_train = y.iloc[0:10000]\n",
    "y_test = y.iloc[10000:12000]\n",
    "\n",
    "df_train = df_filtered.iloc[0:10000]\n",
    "df_test = df_filtered.iloc[10000:12000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer \n",
    "import phik\n",
    "from phik.report import plot_correlation_matrix\n",
    "from scipy.special import ndtr\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import detrendPrice \n",
    "import WhiteRealityCheckFor1 \n",
    "\n",
    "def phi_k(y_true, y_pred):\n",
    "    dfc = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n",
    "    try:\n",
    "        phi_k_corr = dfc.phik_matrix(interval_cols=[]).iloc[1,0]\n",
    "        phi_k_sig  = dfc.significance_matrix(interval_cols=[]).iloc[1,0]\n",
    "        phi_k_p_val = 1 - ndtr(phi_k_sig) \n",
    "    except:\n",
    "        phi_k_corr = 0\n",
    "        phi_k_p_val = 0\n",
    "    print(phi_k_p_val)\n",
    "    return phi_k_corr\n",
    "\n",
    "\n",
    "#myscorer = None #use default accuracy score\n",
    "myscorer = make_scorer(phi_k, greater_is_better=True)\n",
    "\n",
    "numeric_sub_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_sub_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "print(x_train.dtypes)\n",
    "numeric_features_ix = x_train.select_dtypes(include=['float64']).columns\n",
    "categorical_features_ix = x_train.select_dtypes(include=['int64']).columns\n",
    "\n",
    "#Note: transformer 3-element tuples can be: ('name', function or pipeline, column_number_list or column_index)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_sub_pipeline, numeric_features_ix),\n",
    "        ('cat', categorical_sub_pipeline, categorical_features_ix)], remainder='passthrough')\n",
    "\n",
    "\n",
    "logistic = LogisticRegression(max_iter=1000, solver='liblinear') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "INSTRUCTIONS\n",
    "Select the correct pipe with a feature extraction device(sklearn.decomposition.TruncatedSVD) \n",
    "into the regular pipeline, pipe, and do so\n",
    "in the appropriate order (before or after scaling).\n",
    "Call the step 'svd'.\n",
    "TruncatedSVD is documented here:\n",
    "https://archive.is/7LfSc\n",
    "Note that we are applying TruncatedSVD to a mix of one-hot-encoded and continuous predictors.\n",
    "Efficiency in handling sparse matrices makes TruncatedSVD a practical choice, but \n",
    "mixing dense and sparse predictors might reduce this advantage.\n",
    "\"\"\"\n",
    "\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),('svd', TruncatedSVD()),('logistic', logistic)])\n",
    "\n",
    "ncomponents_rs =   list(range(2,x_train.shape[1]))\n",
    "c_rs = np.logspace(3, -4, num=20, endpoint = True)\n",
    "#penalty type=L2 like ridge regression (small coefficients preferred), L1 like lasso  (coefficients can become zero)\n",
    "p_rs= [\"l1\", \"l2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "INSTRUCTIONS\n",
    "Adjust param_grid to reflect the inclusion of TruncatedSVD into the pipeline pipe.\n",
    "Print out the list of possible keys by printing out: grid_search.get_params().keys()\n",
    "\"\"\"\n",
    "\n",
    "param_grid =  [{'svd__n_components': ncomponents_rs, 'logistic__C': c_rs, 'logistic__penalty': p_rs}]\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipe, param_grid, cv=5, scoring=myscorer, return_train_score=True)\n",
    "#grid_search = GridSearchCV(pipe, param_grid, cv=5, scoring=myscorer, return_train_score=True)\n",
    "\n",
    "grid_search.fit(x_train, y_train.values.ravel())\n",
    "\n",
    "best_parameters = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "print(\"Best parameters : {}\".format(best_parameters))\n",
    "#print('Best estimator {}'.format(best_model))\n",
    "print(\"Best cross-validation score : {:.2f}\".format(grid_search.best_score_*100))\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "#print(results.T)\n",
    "results.to_csv(\"results_logisticreg.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
